{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Price Predictor Parameter Optimisation",
   "id": "71b6501c476a85d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T22:22:23.916561Z",
     "start_time": "2025-05-19T22:22:20.124622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import src.utils.file_management as filemgmt\n",
    "import src.pipeline.preprocessing as prep\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Literal, Union\n",
    "\n",
    "from tqdm import tqdm\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib.lines import Line2D\n",
    "    \n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "ec348715c8a0ff56",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T22:22:23.923658Z",
     "start_time": "2025-05-19T22:22:23.920501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ROOT = Path().resolve().parent\n",
    "\n",
    "DATA = ROOT / \"data\"\n",
    "DAILY_PRICES = DATA / \"daily_price_downloads\"\n",
    "MINUTELY_PRICES = DATA / \"minutely_price_downloads\"\n",
    "INTERPOLATED_PRICES = DATA / \"interpolated_prices\"\n",
    "\n",
    "SAVED_MODELS = DATA / \"saved_models\""
   ],
   "id": "e487f3895fe5c86e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Class Setup",
   "id": "14560cebb16d2e16"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-19T22:22:24.113704Z",
     "start_time": "2025-05-19T22:22:24.051025Z"
    }
   },
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    \"\"\" Time-series dataset class based on torch.utils.data.Dataset compatible torch.utils.data.DataLoader \"\"\"\n",
    "    def __init__(self,\n",
    "                 x: Union[pd.DataFrame, pd.Series, np.ndarray],\n",
    "                 y: Union[pd.Series, pd.Series, np.ndarray],\n",
    "                 verbose=False):\n",
    "        # convert values to numpy if necessary:\n",
    "        if isinstance(x, (pd.Series, pd.DataFrame)):\n",
    "            x = x.to_numpy()\n",
    "        if isinstance(y, (pd.Series, pd.DataFrame)):\n",
    "            y = y.to_numpy()\n",
    "            \n",
    "        # expand tensor for LSTM input w. shape (batch, sequence_length, input_size):\n",
    "        x = np.expand_dims(x, 2)\n",
    "        \n",
    "        # sanity check:\n",
    "        if x.shape[0] != y.shape[0]: raise ValueError(\"Mismatched number of samples.\")\n",
    "        \n",
    "        # save values:\n",
    "        self.x = x.astype(np.float32)\n",
    "        self.y = y.astype(np.float32)\n",
    "        \n",
    "        # information:\n",
    "        if verbose: print(f\"Dataset Shape: {self.x.shape}, {self.y.shape}\")\n",
    "        \n",
    "    # necessary operators:\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    \n",
    "    \n",
    "class LSTMModel(nn.Module):\n",
    "    \"\"\" LSTM model class based on torch.nn.Module \"\"\"\n",
    "    def __init__(self,\n",
    "                 input_size=1,\n",
    "                 hidden_layer_size=32,\n",
    "                 num_layers=2,\n",
    "                 n_forecast_steps=1,  # output sequence length\n",
    "                 dropout=0.2,\n",
    "                 use_pre_lstm_fc_layer=False,\n",
    "                 use_final_hidden_state=True,\n",
    "                 use_hidden_states_across_forecast_steps=True,\n",
    "                 init_weights=True):\n",
    "        \"\"\"\n",
    "        Initialise the LSTM model. \n",
    "        \n",
    "        :param input_size: input size of the LSTM model.\n",
    "        :param hidden_layer_size: hidden size of the LSTM model.\n",
    "        :param num_layers: number of LSTM layers.\n",
    "        :param n_forecast_steps: number of forecast steps. If not 1, outputs will be calculated recursively for each forecast step, i.e. while feeding back previous predictions into the network.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.use_pre_lstm_fc_layer = use_pre_lstm_fc_layer\n",
    "        self.use_hidden_states_across_forecast_steps = use_hidden_states_across_forecast_steps\n",
    "        self.n_forecast_steps = n_forecast_steps\n",
    "\n",
    "        # optional pre-lstm fully connected layer:\n",
    "        self.linear_1 = nn.Linear(input_size, hidden_layer_size) if use_pre_lstm_fc_layer else None  # transform feature into size of lstm hidden layers\n",
    "        self.relu = nn.ReLU() if use_pre_lstm_fc_layer else None  # non-linearity\n",
    "\n",
    "        # lstm layers:\n",
    "        self.lstm = nn.LSTM(hidden_layer_size if use_pre_lstm_fc_layer else 1, hidden_size=self.hidden_layer_size, num_layers=num_layers,\n",
    "                            batch_first=True,\n",
    "                            dropout=dropout)  # batch first=True because our shape is (batch, seq, feature)\n",
    "        # self.dropout = nn.Dropout(dropout)  # prevent overfitting, now is included in lstm\n",
    "\n",
    "        self.use_final_hidden_state = use_final_hidden_state  # use lstm_out, else use h_n; see comments below in forward()\n",
    "\n",
    "        # final fully connected layer:\n",
    "        self.linear_2 = nn.Linear((num_layers if use_final_hidden_state else 1) * hidden_layer_size,\n",
    "                                  1)  # transforms LSTM output into 1 price\n",
    "        # when use_final_hidden_state, multiply with * num_layers to utilise all LSTM layer's final hidden states\n",
    "\n",
    "        if init_weights: self.init_weights()  # empirically accelerates convergence\n",
    "\n",
    "    def init_weights(self):\n",
    "        for name, param in self.named_parameters():  # iterate through weights and biases\n",
    "            if 'bias' in name:  # bias zero initialisation: neutral starting point\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:  # input-hidden weights with He/Kaiming initialisation w. normal distribution: preserves gradient magnitude through ReLU activations\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:  # hidden-hidden weights with orthogonal matrix initialisation: maintains norm during sequence processing and helps prevent gradient issues\n",
    "                nn.init.orthogonal_(param)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" Forward call of module \"\"\"\n",
    "        batchsize = x.shape[0]\n",
    "        \n",
    "        outputs = torch.empty(size=(batchsize, self.n_forecast_steps), device=x.device, dtype=x.dtype)  # initialise empty tensor for outputs\n",
    "        \n",
    "        # recursive prediction (taking into account previous predictions if n_forecast_steps > 1):\n",
    "        if self.use_hidden_states_across_forecast_steps:\n",
    "            h_n, c_n = None, None  # initialise hidden cell states that will be used across steps to reduce computational complexity\n",
    "            # this is favourable, because otherwise the complete sequence is reprocessed each iteration\n",
    "            # and LSTMs are designed to remember previous steps through hidden states\n",
    "        for output_sequence_ind in range(self.n_forecast_steps):\n",
    "            # integrate previous predictions into input:\n",
    "            if output_sequence_ind > 0:\n",
    "                x = torch.roll(x, shifts=-1)  # shift all inputs back by one time unit\n",
    "                x[:, -1] = torch.unsqueeze(outputs[:, output_sequence_ind-1], 1)  # replace most recent time step with last prediction\n",
    "                \n",
    "            if self.use_pre_lstm_fc_layer:\n",
    "                # layer 1:\n",
    "                temp_x = self.linear_1(x)  # we need to denote this as temp_x because we need the original input again in latter iterations\n",
    "                # x = self.batch_norm(x)\n",
    "                temp_x = self.relu(temp_x)\n",
    "                # x.shape now is (batch, sequenth_length, features)\n",
    "    \n",
    "            # LSTM layer(s):\n",
    "            if self.use_hidden_states_across_forecast_steps:\n",
    "                # pass last hidden states again to lstm and compute only most recent step\n",
    "                if h_n is None:  # first iteration\n",
    "                    lstm_out, (h_n, c_n) = self.lstm(temp_x)  # compute first step and get hidden and cell states\n",
    "                else:  # further iterations\n",
    "                    lstm_out, (h_n, c_n) = self.lstm(temp_x[:, -1].unsqueeze(1), (h_n, c_n))  # compute new information and leverage previous hidden and cell states\n",
    "            else:\n",
    "                lstm_out, (h_n, c_n) = self.lstm(temp_x)\n",
    "    \n",
    "            # which output to use?\n",
    "            # - lstm_out contains **all hidden states for the last layer** for every time step, used for tasks requiring per-time-step predictions and **sequence forecasting**\n",
    "            #       shape is (batchsize, sequence_length, features)\n",
    "            # - h_n is a tensor containing the **final hidden state for each layer** in the sequence, used for initialing latter sequences, as summarisation for classification tasks or **one-step-forecasting**\n",
    "            #       shape is (num_layers, batchsize, features)\n",
    "            # - c_n is a tensor containing the **final cell state for each layer** in the sequence, used jointly with h_n for more complex forecasting purposes\n",
    "            #       shape is (num_layers, batchsize, features)\n",
    "            if self.use_final_hidden_state:\n",
    "                # we utilise h_n because it aggregates states from all layers.\n",
    "                # reshape final hidden state output from (num_layers, batchsize, features) to (batchsize, features) for consecutive linear layer:\n",
    "                # permute rearranges the dimensions according to a specific order, -1 tells reshape to infer the correct size for that dimension\n",
    "                temp_x = h_n.permute(1, 0, 2).reshape(batchsize, -1)  # here we flatten all layer outputs\n",
    "            else:\n",
    "                # we utilise lstm_out[:, -1, :]  which is the last time step of the final layer\n",
    "                temp_x = lstm_out[:, -1, :]\n",
    "    \n",
    "            # layer 2:\n",
    "            # x = self.dropout(x)  additional regularisation is spared here because happening inside LSTM\n",
    "            predictions = self.linear_2(temp_x)\n",
    "            outputs[:, output_sequence_ind] = predictions.squeeze(-1)  # return last column of all batches (equals predictions), squeeze removes dimensions with size 1\n",
    "        \n",
    "        return outputs.squeeze(-1)  # remove dimensions with size 1\n",
    "\n",
    "    def run_epoch(self, dataloader, optimiser, device='cpu', loss_criterion=nn.MSELoss(), is_training=False):\n",
    "        \"\"\" One epoch of training (is_training=True) or validation (is_training=False), returns the respective loss and learning rate as tuple. \"\"\"\n",
    "        epoch_loss = 0\n",
    "\n",
    "        if is_training:\n",
    "            self.train()  # training mode activates Dropout and BatchNorm (updates running statistics with each batch)\n",
    "        else:\n",
    "            self.eval()  # evaluation mode for inference or testing\n",
    "\n",
    "        # iterate through dataset's batches via provided dataloader instance:\n",
    "        for idx, (x, y) in enumerate(dataloader):\n",
    "            if is_training: optimiser.zero_grad()  # reset all gradients for next training step\n",
    "\n",
    "            # move tensors to correct device:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # compute output and loss:\n",
    "            out = self(x)\n",
    "            loss = loss_criterion(out.contiguous(),\n",
    "                                  y.contiguous())  # enforces the tensors to be stored in a contiguous memory block\n",
    "\n",
    "            if is_training:\n",
    "                loss.backward()  # backpropagation, traverses computational graph in reverse applying the chain rule to compute gradients\n",
    "                optimiser.step()  # optimise weights\n",
    "\n",
    "            epoch_loss += loss.detach().item()  # without / batchsize because loss is already averaged, detach loss value from computational graph\n",
    "\n",
    "        # learning rate:\n",
    "        lr = optimiser.param_groups[0]['lr']\n",
    "\n",
    "        return epoch_loss, lr\n",
    "\n",
    "    def predict(self, dataloader, device='cpu'):\n",
    "        \"\"\" Compute predictions (outputs) for all samples in a dataloader. \"\"\"\n",
    "        self.eval()  # inference mode\n",
    "        \n",
    "        # deactivate shuffling and set batch size to 1:\n",
    "        temp_loader = DataLoader(dataloader.dataset, batch_size=1, shuffle=False)\n",
    "        \n",
    "        # compute predictions:\n",
    "        with torch.no_grad():\n",
    "            for idx, (x, y) in enumerate(tqdm(temp_loader)):\n",
    "                x = x.to(device)\n",
    "                out = self(x)  # run model\n",
    "                out = out.cpu().detach().numpy()\n",
    "                if idx == 0: predictions = np.array(out); continue  # initialise array upon first iteration\n",
    "                predictions = np.concat((predictions, out))\n",
    "\n",
    "            return predictions\n",
    "\n",
    "\n",
    "class HitRateMetric(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\" Hit Rate Metric. Checks how often predictions point into the correct direction of targets. \"\"\"\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, predictions, targets, features):\n",
    "        \"\"\" Can be called but requires predictions, targets AND features to work. \"\"\"\n",
    "        # argument shape: [batch_size, sequence_length]\n",
    "        # convert to tensors:\n",
    "        if not isinstance(predictions, torch.Tensor): predictions = torch.Tensor(predictions)\n",
    "        if not isinstance(targets, torch.Tensor): targets = torch.Tensor(targets)\n",
    "        if not isinstance(features, torch.Tensor): features = torch.Tensor(features)\n",
    "        # compare direction of prediction and targets:\n",
    "        hit_rate_mask = (torch.sign(predictions[:, -1] - features[:, -1]) == torch.sign(targets[:, -1] - features[:, -1])) # true if last prediction and last target point in same direction starting from last feature\n",
    "        return hit_rate_mask.sum() / hit_rate_mask.numel()  # hit rate as ratio\n",
    "    \n",
    "\n",
    "class WeightedMSELoss(nn.Module):\n",
    "    def __init__(self, step_weights=None):\n",
    "        \"\"\" Weighted MSE Loss. If step_weights is None, weights all predictions equally. \"\"\"\n",
    "        super().__init__()\n",
    "        self.step_weights = step_weights\n",
    "        \n",
    "    def forward(self, predictions, targets):\n",
    "        # predictions and target shape: [batch_size, n_steps]\n",
    "        # convert to tensor dtype:\n",
    "        if not isinstance(predictions, torch.Tensor): predictions = torch.tensor(predictions)\n",
    "        if not isinstance(targets, torch.Tensor): targets = torch.tensor(targets)\n",
    "        # calculate loss:\n",
    "        if self.step_weights is None:  # equal weighting\n",
    "            return torch.mean((predictions - targets) ** 2)  # MSE formula\n",
    "        else:  # weighted loss\n",
    "            losses = (predictions - targets) ** 2\n",
    "            weighted_losses = losses * torch.Tensor(self.step_weights, device=predictions.device)  # calculate weighted loss tensor\n",
    "            return torch.mean(weighted_losses)\n",
    "\n",
    "\n",
    "class Normaliser():\n",
    "    def __init__(self):\n",
    "        self.mu = None\n",
    "        self.sd = None\n",
    "\n",
    "    def fit_transform(self, x):\n",
    "        \"\"\" Normalise an array of values. \"\"\"\n",
    "        self.mu = np.mean(x, axis=0)\n",
    "        self.sd = np.std(x, axis=0)\n",
    "        normalized_x = (x - self.mu)/self.sd\n",
    "        return normalized_x\n",
    "\n",
    "    def transform(self, x):\n",
    "        \"\"\" Normalise additional data of same sequence as before. \"\"\"\n",
    "        if self.sd is None: raise AttributeError(\"Please use fit_transform first so this instance remembers the respective std. and mean values!\")\n",
    "        normalized_x = (x - self.mu)/self.sd\n",
    "        return normalized_x\n",
    "        \n",
    "    def inverse_transform(self, x):\n",
    "        \"\"\" Reverse-transform an array of normalised values. \"\"\"\n",
    "        if self.sd is None: raise AttributeError(\"Please use fit_transform first so this instance remembers the respective std. and mean values!\")\n",
    "        return (x*self.sd) + self.mu\n",
    "    \n",
    "\n",
    "class LSTMPredictor:\n",
    "    \"\"\" LSTM based stock price predictor framework. \"\"\"\n",
    "    def __init__(self,\n",
    "                 sampling_rate_minutes: int = 15,  # data import parameters\n",
    "                 price_csv_path: str = None,\n",
    "                 price_column: str = 'close',\n",
    "                 date_column: str = 'date',\n",
    "                 daily_prediction_hour: int = None,  # data preparation parameters\n",
    "                 rolling_window_size: int = 32,\n",
    "                 forecast_horizon: int = 12,\n",
    "                 validation_split: float = 0.2,\n",
    "                 batch_size: int = 32,\n",
    "                 model_load_file_path: str = None,  # model parameters\n",
    "                 hidden_lstm_layer_size: int = 64,\n",
    "                 n_lstm_layers: int = 3,\n",
    "                 dropout: float = 0.3,\n",
    "                 use_final_hidden_state: bool = False,\n",
    "                 use_pre_lstm_fc_layer: bool = True,\n",
    "                 init_weights: bool = True,\n",
    "                 use_mps_if_available: bool = False,\n",
    "                 model_save_directory: str = None,\n",
    "                 forecast_step_loss_weight_range: (float) = (1, 0.7),  # training parameters\n",
    "                 n_train_epochs: int = None,  # if set to some number, trains upon initialisation\n",
    "                 lr_scheduler: Literal['step', 'plateau'] = 'plateau',\n",
    "                 initial_lr: float = 0.001,\n",
    "                 step_scheduler_step_size: int = 40,\n",
    "                 plateau_scheduler_factor: float = 0.5,\n",
    "                 early_stopping_patience: int = 30,  # if 0 doesn't utilise early stopping\n",
    "                 verbose = True,  # other parameters\n",
    "                 ):\n",
    "        self._sampling_rate_minutes = sampling_rate_minutes\n",
    "        self._price_csv_path = price_csv_path\n",
    "        self._price_column = price_column\n",
    "        self._date_column = date_column\n",
    "        \n",
    "        self._daily_prediction_hour = daily_prediction_hour\n",
    "        self._rolling_window_size = rolling_window_size\n",
    "        self._forecast_horizon = forecast_horizon\n",
    "        self._validation_split = validation_split\n",
    "        self._batch_size = batch_size\n",
    "        \n",
    "        if model_load_file_path is not None: self.load_model_from_pt_file(model_load_file_path)\n",
    "        self._hidden_lstm_layer_size = hidden_lstm_layer_size\n",
    "        self._n_lstm_layers = n_lstm_layers\n",
    "        self._dropout = dropout\n",
    "        self._use_final_hidden_state = use_final_hidden_state\n",
    "        self._use_pre_lstm_fc_layer = use_pre_lstm_fc_layer\n",
    "        self._init_weights = init_weights\n",
    "        self._use_mps_if_available = use_mps_if_available\n",
    "        \n",
    "        self.model_save_directory = model_save_directory\n",
    "        self._forecast_step_loss_weight_range = forecast_step_loss_weight_range\n",
    "        self._n_train_epochs = n_train_epochs\n",
    "        self._lr_scheduler = lr_scheduler\n",
    "        self._initial_lr = initial_lr\n",
    "        self._step_scheduler_step_size = step_scheduler_step_size\n",
    "        self._plateau_scheduler_factor = plateau_scheduler_factor\n",
    "        self._early_stopping_patience = early_stopping_patience\n",
    "        \n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self._price_series = self._normalised_price_series = None\n",
    "        self._normaliser = Normaliser()\n",
    "        self._X = self._Y = self._X_dates = self._Y_dates = None\n",
    "        self._X_train = self._X_val = self._Y_train = self._Y_val = self._X_dates_train = self._X_dates_val = self._Y_dates_train = self._Y_dates_val = None\n",
    "        self._dataloader_train = self._dataloader_val = None\n",
    "        \n",
    "        self._lstm_model = None\n",
    "        self._device = None\n",
    "        self._loss_criterion = None\n",
    "        \n",
    "        self._predictions_train = self._predictions_val = None\n",
    "        self._loss_train = self._loss_val = None\n",
    "        self._hit_rate_train = self._hit_rate_val = None\n",
    "        \n",
    "        if price_csv_path is None and verbose: print('No price file provided yet. Define LSTMPredictor.price_csv_path to trigger data import.')\n",
    "        if daily_prediction_hour is None and verbose: print('No daily prediction hour defined yet, hence currently predictions are carried out at every time step. Define LSTMPredictor.daily_prediction_hour to change this.')\n",
    "        if n_train_epochs is None and verbose: print('No training epochs defined upon initialisation. Define LSTMPredictor.n_train_epochs to start training procedure.')\n",
    "        elif n_train_epochs is not None:  # automatically start training\n",
    "            self.run_training()\n",
    "            if verbose:\n",
    "                print('Training finished. Plotting results for validation split:')\n",
    "                self.plot_prediction_overview(day_slice=(0, 5))\n",
    "    \n",
    "    # str and print operators:\n",
    "    def __str__(self):\n",
    "        return self.describe()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.describe()\n",
    "        \n",
    "    def describe(self):\n",
    "        intro_str = \"------------------- LSTMPredictor Instance -------------------\\n\\n\"\n",
    "        data_str = f\"Data Attributes:\\n- sampling rate in minutes: {self.sampling_rate_minutes}\\n- daily prediction hour: {f'{self._daily_prediction_hour}:00' if self.daily_prediction_hour is not None else 'None'}\\n- rolling window size: {self._rolling_window_size}\\n- forecast horizon: {self._forecast_horizon}\\n- validation split: {self._validation_split}\\n- amount of training observations: {len(self.X_train)}\\n- amount of validation observations: {len(self.X_val)}\\n\\n\"\n",
    "        model_str = f\"Model Attributes:\\n- hidden LSTM layers: {self._hidden_lstm_layer_size}\\n- number of LSTM layers: {self._n_lstm_layers}\\n- pre LSTM fully connected layer: {self.use_pre_lstm_fc_layer}\\n\\n\"\n",
    "        training_str = f\"Training Attributes:\\n- final training loss: {self.loss_train}\\n- final validation loss: {self.loss_val}\\n- final training hit-rate: {self.hit_rate_train}\\n- final validation hit-rate: {self.hit_rate_val}\"\n",
    "        return intro_str + data_str + model_str + training_str\n",
    "    \n",
    "    # data import parameters:\n",
    "    @property\n",
    "    def sampling_rate_minutes(self): return self._sampling_rate_minutes\n",
    "\n",
    "    @property\n",
    "    def price_csv_path(self): return self._price_csv_path\n",
    "    \n",
    "    @price_csv_path.setter\n",
    "    def price_csv_path(self, value): self._price_csv_path = value; self.import_data()\n",
    "    \n",
    "    @property\n",
    "    def price_column(self): return self._price_column\n",
    "    \n",
    "    @price_column.setter\n",
    "    def price_column(self, value):\n",
    "        self._price_column = value\n",
    "        if self._price_series is not None: self._price_series.name = value\n",
    "\n",
    "    @property\n",
    "    def date_column(self): return self._date_column\n",
    "    \n",
    "    @date_column.setter\n",
    "    def date_column(self, value):\n",
    "        self._date_column = value\n",
    "        if self._price_series is not None: self._price_series.index.name = value\n",
    "            \n",
    "    @property\n",
    "    def price_series(self):\n",
    "        if self._price_series is None:\n",
    "            if self.price_csv_path is None: raise AttributeError(\"LSTMPredictor.price_csv_path needs to be provided to import price data.\")\n",
    "            else: self.import_data()\n",
    "        return self._price_series\n",
    "            \n",
    "    # data preparation parameters:\n",
    "    @property\n",
    "    def normalised_price_series(self):\n",
    "        if self._normalised_price_series is None:\n",
    "            self._normalised_price_series = self._normaliser.fit_transform(self.price_series)\n",
    "        return self._normalised_price_series\n",
    "    \n",
    "    @property\n",
    "    def normaliser(self): return self._normaliser\n",
    "    \n",
    "    @property\n",
    "    def daily_prediction_hour(self): return self._daily_prediction_hour\n",
    "\n",
    "    @daily_prediction_hour.setter\n",
    "    def daily_prediction_hour(self, value): self._daily_prediction_hour = value; self.prepare_data()\n",
    "    \n",
    "    @property\n",
    "    def rolling_window_size(self): return self._rolling_window_size\n",
    "    \n",
    "    @rolling_window_size.setter\n",
    "    def rolling_window_size(self, value): self._rolling_window_size = value; self.prepare_data()\n",
    "\n",
    "    @property\n",
    "    def forecast_horizon(self): return self._forecast_horizon\n",
    "    \n",
    "    @forecast_horizon.setter\n",
    "    def forecast_horizon(self, value): self._forecast_horizon = value; self.prepare_data()\n",
    "    \n",
    "    @property\n",
    "    def X(self):\n",
    "        if self._X is None: self.prepare_data()\n",
    "        return self._X\n",
    "    \n",
    "    @property\n",
    "    def Y(self):\n",
    "        if self._Y is None: self.prepare_data()\n",
    "        return self._Y\n",
    "    \n",
    "    @property\n",
    "    def X_dates(self):\n",
    "        if self._X_dates is None: self.prepare_data()\n",
    "        return self._X_dates\n",
    "    \n",
    "    @property\n",
    "    def Y_dates(self):\n",
    "        if self._Y_dates is None: self.prepare_data()\n",
    "        return self._Y_dates\n",
    "    \n",
    "    @property\n",
    "    def validation_split(self): return self._validation_split\n",
    "    \n",
    "    @validation_split.setter\n",
    "    def validation_split(self, value): self._validation_split = value; self.split_data()\n",
    "    \n",
    "    @property\n",
    "    def X_train(self):\n",
    "        if self._X_train is None: self.split_data()\n",
    "        return self._X_train\n",
    "\n",
    "    @property\n",
    "    def X_val(self):\n",
    "        if self._X_val is None: self.split_data()\n",
    "        return self._X_val\n",
    "\n",
    "    @property\n",
    "    def Y_train(self):\n",
    "        if self._Y_train is None: self.split_data()\n",
    "        return self._Y_train\n",
    "\n",
    "    @property\n",
    "    def Y_val(self):\n",
    "        if self._Y_val is None: self.split_data()\n",
    "        return self._Y_val\n",
    "\n",
    "    @property\n",
    "    def X_dates_train(self):\n",
    "        if self._X_dates_train is None: self.split_data()\n",
    "        return self._X_dates_train\n",
    "\n",
    "    @property\n",
    "    def X_dates_val(self):\n",
    "        if self._X_dates_val is None: self.split_data()\n",
    "        return self._X_dates_val\n",
    "\n",
    "    @property\n",
    "    def Y_dates_train(self):\n",
    "        if self._Y_dates_train is None: self.split_data()\n",
    "        return self._Y_dates_train\n",
    "\n",
    "    @property\n",
    "    def Y_dates_val(self):\n",
    "        if self._Y_dates_val is None: self.split_data()\n",
    "        return self._Y_dates_val\n",
    "    \n",
    "    @property\n",
    "    def dataset_train(self):\n",
    "        return TimeSeriesDataset(self.X_train, self.Y_train)\n",
    "    \n",
    "    @property\n",
    "    def dataset_val(self):\n",
    "        return TimeSeriesDataset(self.X_val, self.Y_val)\n",
    "    \n",
    "    @property\n",
    "    def batch_size(self): return self._batch_size\n",
    "    \n",
    "    @batch_size.setter\n",
    "    def batch_size(self, value):\n",
    "        \"\"\" Changing value re-initialises dataloaders. \"\"\"\n",
    "        self._batch_size = value\n",
    "        self._dataloader_train = self._dataloader_val = None\n",
    "    \n",
    "    @property\n",
    "    def dataloader_train(self):\n",
    "        if self._dataloader_train is None: self._dataloader_train = DataLoader(self.dataset_train, batch_size=self.batch_size, shuffle=True)\n",
    "        return self._dataloader_train\n",
    "        \n",
    "    @property\n",
    "    def dataloader_val(self):\n",
    "        if self._dataloader_val is None: self._dataloader_val = DataLoader(self.dataset_val, batch_size=self.batch_size, shuffle=True)\n",
    "        return self._dataloader_val\n",
    "        \n",
    "    # model parameters:\n",
    "    @property\n",
    "    def hidden_lstm_layer_size(self): return self._hidden_lstm_layer_size\n",
    "    \n",
    "    @hidden_lstm_layer_size.setter\n",
    "    def hidden_lstm_layer_size(self, value):\n",
    "        \"\"\" Changing value re-initialises LSTM model. \"\"\"\n",
    "        self._hidden_lstm_layer_size = value\n",
    "        self._lstm_model = None\n",
    "    \n",
    "    @property\n",
    "    def n_lstm_layers(self): return self._n_lstm_layers\n",
    "    \n",
    "    @n_lstm_layers.setter\n",
    "    def n_lstm_layers(self, value):\n",
    "        \"\"\" Changing value re-initialises LSTM model. \"\"\"\n",
    "        self._n_lstm_layers = value\n",
    "        self._lstm_model = None\n",
    "    \n",
    "    @property\n",
    "    def dropout(self): return self._dropout\n",
    "    \n",
    "    @dropout.setter\n",
    "    def dropout(self, value):\n",
    "        \"\"\" Changing value re-initialises LSTM model. \"\"\"\n",
    "        self._dropout = value\n",
    "        self._lstm_model = None\n",
    "        \n",
    "    @property\n",
    "    def use_final_hidden_state(self): return self._use_final_hidden_state\n",
    "\n",
    "    @use_final_hidden_state.setter\n",
    "    def use_final_hidden_state(self, value):\n",
    "        \"\"\" Changing value re-initialises LSTM model. \"\"\"\n",
    "        self._use_final_hidden_state = value\n",
    "        self._lstm_model = None\n",
    "\n",
    "    @property\n",
    "    def use_pre_lstm_fc_layer(self): return self._use_pre_lstm_fc_layer\n",
    "\n",
    "    @use_pre_lstm_fc_layer.setter\n",
    "    def use_pre_lstm_fc_layer(self, value):\n",
    "        \"\"\" Changing value re-initialises LSTM model. \"\"\"\n",
    "        self._use_pre_lstm_fc_layer = value\n",
    "        self._lstm_model = None\n",
    "\n",
    "    @property\n",
    "    def init_weights(self): return self._init_weights\n",
    "\n",
    "    @init_weights.setter\n",
    "    def init_weights(self, value):\n",
    "        \"\"\" Changing value re-initialises LSTM model. \"\"\"\n",
    "        self._init_weights = value\n",
    "        self._lstm_model = None\n",
    "    \n",
    "    @property\n",
    "    def lstm_model(self):\n",
    "        if self._lstm_model is None:\n",
    "            self._lstm_model = LSTMModel(input_size=1, hidden_layer_size=self.hidden_lstm_layer_size,\n",
    "                                         num_layers=self._n_lstm_layers, n_forecast_steps=self.forecast_horizon,\n",
    "                                         dropout=self.dropout, use_pre_lstm_fc_layer=self.use_pre_lstm_fc_layer,\n",
    "                                         use_final_hidden_state=self.use_final_hidden_state,\n",
    "                                         use_hidden_states_across_forecast_steps=True,\n",
    "                                         init_weights=self.init_weights)\n",
    "            self._lstm_model.to(self.device)\n",
    "            self._lstm_model = torch.compile(self._lstm_model)\n",
    "        return self._lstm_model\n",
    "    \n",
    "    @lstm_model.setter\n",
    "    def lstm_model(self, value):\n",
    "        self._lstm_model = value\n",
    "        # set other properties based on model parameters:\n",
    "        try:\n",
    "            a = value.linear_1  # try accessing layer\n",
    "            self._use_pre_lstm_fc_layer = True if a is not None else False\n",
    "        except AttributeError:  # if not found\n",
    "            self._use_pre_lstm_fc_layer = False\n",
    "        self._hidden_lstm_layer_size = value.lstm.hidden_size\n",
    "        self._n_lstm_layers = value.lstm.num_layers\n",
    "        self._dropout = value.lstm.dropout\n",
    "    \n",
    "    @property\n",
    "    def use_mps_if_available(self): return self._use_mps_if_available\n",
    "    \n",
    "    @use_mps_if_available.setter\n",
    "    def use_mps_if_available(self, value):\n",
    "        \"\"\" Changing value re-initialises device. \"\"\"\n",
    "        self._use_mps_if_available = value; self._device = None; self._lstm_model.to(self.device)\n",
    "        \n",
    "    @property\n",
    "    def device(self):\n",
    "        if self._device is None:\n",
    "            if torch.cuda.is_available():\n",
    "                self._device = torch.device('cuda')  # if ROCm is installed and AMD hardware is supported by such then 'cuda' also refers to AMD GPU acceleration. This however is not possible on mac\n",
    "                if self.verbose: print(\"Using GPU:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "            elif torch.backends.mps.is_available() and self.use_mps_if_available:\n",
    "                self._device = torch.device('mps')\n",
    "                if self.verbose: print(\"Using GPU through Metal Performance Shaders (MPS) backend\")\n",
    "            else:\n",
    "                self._device = torch.device('cpu')\n",
    "                if self.verbose: print(\"Using CPU\")\n",
    "        return self._device\n",
    "    \n",
    "    # training parameters:\n",
    "    @property\n",
    "    def forecast_step_loss_weight_range(self): return self._forecast_step_loss_weight_range\n",
    "    \n",
    "    @forecast_step_loss_weight_range.setter\n",
    "    def forecast_step_loss_weight_range(self, value):\n",
    "        \"\"\" Changing value re-initialises loss criterion. \"\"\"\n",
    "        self._forecast_step_loss_weight_range = value; self._loss_criterion = None\n",
    "    \n",
    "    @property\n",
    "    def loss_criterion(self):\n",
    "        \"\"\" Forecast step loss weighted according to LSTMPredictor.forecast_step_loss_weight_range. \"\"\"\n",
    "        if self._loss_criterion is None: self._loss_criterion = WeightedMSELoss(step_weights=np.linspace(self.forecast_step_loss_weight_range[0],\n",
    "                                                                                                         self.forecast_step_loss_weight_range[1],\n",
    "                                                                                                         self.forecast_horizon))\n",
    "        return self._loss_criterion\n",
    "    \n",
    "    @property\n",
    "    def n_train_epochs(self): return self._n_train_epochs\n",
    "\n",
    "    @n_train_epochs.setter\n",
    "    def n_train_epochs(self, value): self._n_train_epochs = value; self.run_training()\n",
    "    \n",
    "    @property\n",
    "    def lr_scheduler(self): return self._lr_scheduler\n",
    "\n",
    "    @property\n",
    "    def initial_lr(self): return self._initial_lr\n",
    "\n",
    "    @property\n",
    "    def step_scheduler_step_size(self): return self._step_scheduler_step_size\n",
    "\n",
    "    @property\n",
    "    def plateau_scheduler_factor(self): return self._plateau_scheduler_factor\n",
    "\n",
    "    @property\n",
    "    def early_stopping_patience(self): return self._early_stopping_patience\n",
    "    \n",
    "    @property\n",
    "    def predictions_train(self):\n",
    "        if self._predictions_train is None:\n",
    "            self._predictions_train = self._lstm_model.predict(self.dataloader_train, device=self.device)\n",
    "        return self._predictions_train\n",
    "    \n",
    "    @property\n",
    "    def predictions_val(self):\n",
    "        if self._predictions_val is None:\n",
    "            self._predictions_val = self._lstm_model.predict(self.dataloader_val, device=self.device)\n",
    "        return self._predictions_val\n",
    "    \n",
    "    # evaluation properties:\n",
    "    @property\n",
    "    def loss_train(self):\n",
    "        \"\"\" Final training loss value \"\"\"\n",
    "        if self._loss_train is None:\n",
    "            self._loss_train = self.loss_criterion(self.predictions_train, self.Y_train)\n",
    "        return self._loss_train\n",
    "    \n",
    "    @property\n",
    "    def loss_val(self):\n",
    "        \"\"\" Final validation loss value \"\"\"\n",
    "        if self._loss_val is None:\n",
    "            self._loss_val = self.loss_criterion(self.predictions_val, self.Y_val)\n",
    "        return self._loss_val\n",
    "    \n",
    "    @property\n",
    "    def hit_rate_train(self):\n",
    "        \"\"\" How often model predicts right direction of price development (hit rate) in training samples. \"\"\"\n",
    "        if self._hit_rate_train is None:\n",
    "            self._hit_rate_train = HitRateMetric()(self.predictions_train, self.Y_train, self.X_train)\n",
    "        return self._hit_rate_train\n",
    "    \n",
    "    @property\n",
    "    def hit_rate_val(self):\n",
    "        \"\"\" How often model predicts right direction of price development (hit rate) in validation samples. \"\"\"\n",
    "        if self._hit_rate_val is None:\n",
    "            self._hit_rate_val = HitRateMetric()(self.predictions_val, self.Y_val, self.X_val)\n",
    "        return self._hit_rate_val\n",
    "    \n",
    "    def import_data(self):\n",
    "        \"\"\" Import data from LSTMPredictor.price_csv_path file. \"\"\"\n",
    "        price_file = pd.read_csv(self._price_csv_path).dropna(axis=0)\n",
    "        try:\n",
    "            price_file[self._date_column] = pd.to_datetime(price_file[self._date_column])\n",
    "        except KeyError:  # if the csv has no name for its index:\n",
    "            price_file[self._date_column] = pd.to_datetime(price_file['Unnamed: 0'])\n",
    "        price_file[self._price_column] = price_file[self._price_column].astype(float) \n",
    "        self._price_series = price_file.set_index(self._date_column)[self._price_column]\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        \"\"\"\n",
    "        Creates a rolling window matrix of training data and target values based on a time-series with datetime index.\n",
    "        Columns of training data are defined by rolling_window_size, columns of target data by forecast_horizon.\n",
    "        \n",
    "        For intra-day predictions, the method allows for defining the ending point of each rolling window (and \n",
    "        hence starting point of target values) with daily_prediction_hour. E.g. daily_prediction_hour=15 will lead\n",
    "        to the targets always starting at the first sample after 3 pm.\n",
    "        This further requires specifying sampling_rate_minutes to find the first entry in that prediction hour.\n",
    "        \"\"\"\n",
    "        # sliding window view as matrix: last column are current prices, 1st to (rolling-window-size - 1)th column are retrospective prices:\n",
    "        self._X = np.lib.stride_tricks.sliding_window_view(self.normalised_price_series.to_numpy(), window_shape=self._rolling_window_size)[\n",
    "            :-self._forecast_horizon]  # last rows (latest values) are removed (because contained only in target values)\n",
    "        self._X_dates = np.lib.stride_tricks.sliding_window_view(self.normalised_price_series.index.to_numpy(), window_shape=self._rolling_window_size)[\n",
    "            :-self._forecast_horizon]\n",
    "    \n",
    "        # target values are subsequent prices, window size here is referred to as the forecast_horizon:\n",
    "        self._Y = np.lib.stride_tricks.sliding_window_view(self.normalised_price_series.to_numpy(), window_shape=self._forecast_horizon)[\n",
    "            self._rolling_window_size:]  # first rows (earliest values) are removed (because contained only in training values)\n",
    "        self._Y_dates = np.lib.stride_tricks.sliding_window_view(self.normalised_price_series.index.to_numpy(), window_shape=self._forecast_horizon)[\n",
    "            self._rolling_window_size:]  # first rows (earliest values) are removed (because contained only in training values)\n",
    "        if self.verbose: print(f\"Created rolling window view based on rolling_window_size of {self.rolling_window_size} and forecast_horizon of {self.forecast_horizon} with a time unit of {self.sampling_rate_minutes} minutes.\")\n",
    "        \n",
    "        if self._daily_prediction_hour is not None:\n",
    "            # specify prediction start mask:\n",
    "            target_date_index = self.normalised_price_series[\n",
    "                            self._rolling_window_size:-self._forecast_horizon + 1].index  # first and last rows are removed here according to the rolling windows\n",
    "            prediction_start_mask = (target_date_index.hour == self._daily_prediction_hour) & (\n",
    "                        target_date_index.minute < self._sampling_rate_minutes)  # first observation in prediction_hour\n",
    "    \n",
    "            # select only training values related to target values starting at the specified prediction time:\n",
    "            self._X = self._X[prediction_start_mask]\n",
    "            self._Y = self._Y[prediction_start_mask]\n",
    "            self._X_dates = self._X_dates[prediction_start_mask]\n",
    "            self._Y_dates = self._Y_dates[prediction_start_mask]\n",
    "            if self.verbose: print(f\"Target values start at first observation after {self._daily_prediction_hour}:00 daily.\\nResulting dataset consists of {len(self._X)} observations.\")\n",
    "    \n",
    "    def split_data(self):\n",
    "        \"\"\" Splits training and target values into training and validation split. \"\"\"\n",
    "        validation_split_index = int(self.X.shape[0] * (1-self._validation_split))\n",
    "        self._X_train = self.X[:validation_split_index]\n",
    "        self._X_val = self.X[validation_split_index:]\n",
    "        self._Y_train = self.Y[:validation_split_index]\n",
    "        self._Y_val = self.Y[validation_split_index:]\n",
    "        if self.verbose: print(f\"Using last {100 * self._validation_split}% of data for validation. Other data for training.\")\n",
    "        if self.verbose: print(f\"This yields {len(self._X_train)} training and {len(self._X_val)} validation observations.\")\n",
    "        \n",
    "        # split respective dates:\n",
    "        self._X_dates_train = self._X_dates[:validation_split_index]\n",
    "        self._X_dates_val = self._X_dates[validation_split_index:]\n",
    "        self._Y_dates_train = self._Y_dates[:validation_split_index]\n",
    "        self._Y_dates_val = self._Y_dates[validation_split_index:]\n",
    "        \n",
    "    def plot_train_validation_overview(self):\n",
    "        \"\"\" Plot training and validation data highlighted by colors. \"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(12,6))\n",
    "        ax.plot(self.Y_dates_train[:, 0], self._normaliser.inverse_transform(self.Y_train[:, 0]), label='Training Data', color='blue')  # use first column (first price in forecast sequence)\n",
    "        ax.plot(self.Y_dates_val[:, 0], self._normaliser.inverse_transform(self.Y_val[:, 0]), label='Validation Data', color='red')\n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_ylabel('Price')\n",
    "        ax.set_title('Data Overview')\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "    \n",
    "    def load_model_from_pt_file(self, file_path: str):\n",
    "        \"\"\" Load LSTM model from .pt file. \"\"\"\n",
    "        self.lstm_model = torch.load(file_path, weights_only=False) \n",
    "        \n",
    "    def save_lstm_model_file(self, custom_save_directory: str = None, custom_title_identifier: str = None):\n",
    "        \"\"\" Save model to LSTMPredictor.model_save_directory or provided custom_save_directory. \"\"\"\n",
    "        assert custom_save_directory is not None or self.model_save_directory is not None; \"Either custom_save_directory needs to be passed to function or LSTMPredictor.model_save_directory needs to be defined!\"\n",
    "        save_path = custom_save_directory if custom_save_directory is not None else self.model_save_directory\n",
    "        save_title = filemgmt.file_title(f\"LSTM Model RW{self.rolling_window_size} FH{self.forecast_horizon} Layers{self.n_lstm_layers} Size{self.hidden_lstm_layer_size}{f' {custom_title_identifier}' if custom_title_identifier is not None else ''}\", dtype_suffix=\".pt\")\n",
    "        if self.verbose: print(f\"Saving LSTM model to {save_path}/{save_title}.pt\")\n",
    "        torch.save(self.lstm_model, save_path / save_title)\n",
    "    \n",
    "    def run_training(self, custom_n_epochs: int = None):\n",
    "        \"\"\" Train LSTM model. \"\"\"\n",
    "        if custom_n_epochs is not None: self._n_train_epochs = custom_n_epochs  # don't set property here but attribute because otherwise run_training is re-triggered \n",
    "        # initialise optimiser and scheduler:\n",
    "        optimiser = optim.Adam(self.lstm_model.parameters(), lr=self.initial_lr, betas=(0.9, 0.98), eps=1e-9)  # beta and eps are standard values derived from github\n",
    "        if self.lr_scheduler == 'step':\n",
    "            scheduler = optim.lr_scheduler.StepLR(optimiser, self.step_scheduler_step_size, gamma=0.1)\n",
    "        elif self.lr_scheduler == 'plateau':\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimiser, factor=self.plateau_scheduler_factor, patience=5)\n",
    "        else:\n",
    "            raise ValueError(\"scheduler_to_use has to be either 'step' or 'plateau'!\")\n",
    "    \n",
    "        # training loop:\n",
    "        progress_bar = tqdm(range(self.n_train_epochs), desc=f'Train loss: - | Val Loss: - | Patience {'/' if self.early_stopping_patience == 0 else f'{0}/{self.early_stopping_patience}'} | LRate: - | Progress')\n",
    "        loss_train_history, loss_val_history = [], []\n",
    "        for epoch in progress_bar:\n",
    "            loss_train, lr_train = self.lstm_model.run_epoch(self.dataloader_train, optimiser=optimiser, device=self.device, loss_criterion=self.loss_criterion, is_training=True)\n",
    "            loss_val, _ = self.lstm_model.run_epoch(self.dataloader_val, optimiser=optimiser, device=self.device, loss_criterion=self.loss_criterion, is_training=False)\n",
    "    \n",
    "            # scheduler step:\n",
    "            if self.lr_scheduler == 'plateau': scheduler.step(loss_val)\n",
    "            else: scheduler.step()\n",
    "    \n",
    "            loss_train_history.append(loss_train); loss_val_history.append(loss_val)\n",
    "    \n",
    "            # early stopping check:\n",
    "            if self.early_stopping_patience != 0:\n",
    "                # initialisation of vars in epoch 0:\n",
    "                if epoch == 0:\n",
    "                    best_loss = loss_val\n",
    "                    counter = 0\n",
    "                    continue\n",
    "                # validation loss improved:\n",
    "                if loss_val < best_loss:\n",
    "                    best_loss = loss_val\n",
    "                    counter = 0\n",
    "                else:  # validation loss didn't improve\n",
    "                    counter += 1\n",
    "                    if counter >= self.early_stopping_patience:\n",
    "                        print(\"Early stopping triggered at validation loss of\", loss_val)\n",
    "                        self._n_train_epochs = epoch + 1\n",
    "                        break\n",
    "    \n",
    "            # progress bar for visualisation:\n",
    "            progress_bar.desc = f'Train loss: {loss_train} | Val Loss: {loss_val}  | Patience {'/' if self.early_stopping_patience == 0 else f'{counter}/{self.early_stopping_patience}'} | LRate: {lr_train} | Progress'\n",
    "        \n",
    "        # save final losses:\n",
    "        self._loss_train = loss_train_history[:-1]\n",
    "        self._loss_val = loss_val_history[:-1]\n",
    "        \n",
    "        # save model:\n",
    "        if self.model_save_directory is not None:\n",
    "            self.save_lstm_model_file(custom_title_identifier=f\"TrainL{loss_train} ValL{loss_val} TrainHR {self.hit_rate_train} ValHR {self.hit_rate_val}\")\n",
    "                \n",
    "        # loss progression plot and training info:\n",
    "        if self.verbose:\n",
    "            print(f\"Training finished.\\nFinal loss training data: {loss_train}\\t\\t\\t\\tValidation data: {loss_val}\\nFinal hit-rate training data: {self.hit_rate_train}\\t\\t\\tValidation data: {self.hit_rate_val}\")\n",
    "            fig, ax = plt.subplots(figsize=(12,6))\n",
    "            ax.plot(range(self.n_train_epochs), loss_train_history, label='Training loss', color='blue')\n",
    "            ax.plot(range(self.n_train_epochs), loss_val_history, label='Validation loss', color='red')\n",
    "            ax.set_xlabel('Epochs')\n",
    "            ax.set_ylabel('Loss')\n",
    "            ax.grid(True)\n",
    "            ax.legend()\n",
    "            ax.set_title('Training Progress')\n",
    "            \n",
    "    def plot_prediction_overview(self, data_split: Literal['training', 'validation'] = 'validation',\n",
    "                                 day_slice: (int, int) = None,\n",
    "                                 X_color: str = 'blue', Y_color: str = 'green', pred_color: str = 'red',\n",
    "                                 plot_size: (int, int) = (12, 6),\n",
    "                                 ) -> None:\n",
    "        \"\"\" Plot prediction overview on training or validation data. \"\"\"\n",
    "        predictions_per_day = 1\n",
    "        \n",
    "        # select training or validation data:\n",
    "        predictions = self.predictions_train if data_split == 'training' else self.predictions_val\n",
    "        X_dates = self.X_dates_train if data_split == 'training' else self.X_dates_val\n",
    "        X = self.X_train if data_split == 'training' else self.X_val\n",
    "        Y_dates = self.Y_dates_train if data_split == 'training' else self.Y_dates_val\n",
    "        Y = self.Y_train if data_split == 'training' else self.Y_val\n",
    "        \n",
    "        # prepare day_slice:\n",
    "        if day_slice is None or len(day_slice) != 2:\n",
    "            day_slice = (0, len(predictions))\n",
    "            \n",
    "        # plot result for daily multi-step predictions:\n",
    "        fig, ax = plt.subplots(figsize=plot_size)\n",
    "        for ind, (x_datetime, features, y_datetime, pred, target) in enumerate(zip(X_dates, X, Y_dates, predictions, Y)):\n",
    "            # plot only days within day_slice:\n",
    "            if ind / predictions_per_day < day_slice[0]: continue\n",
    "            if ind / predictions_per_day >= day_slice[1]: break  # plot only that many days\n",
    "            # plot features:\n",
    "            ax.plot(x_datetime, self._normaliser.inverse_transform(features), color=X_color)\n",
    "            # plot prediction and target:\n",
    "            ax.plot(y_datetime, self._normaliser.inverse_transform(target), color=Y_color)\n",
    "            ax.plot(y_datetime, self._normaliser.inverse_transform(pred), color=pred_color)\n",
    "    \n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_ylabel('Price')\n",
    "        ax.set_title('Result Overview')\n",
    "        legend_elements = [Line2D([0], [0], color=X_color, label='Training Prices'),\n",
    "                           Line2D([0], [0], color=Y_color, label='Target Prices'),\n",
    "                           Line2D([0], [0], color=pred_color, label='Predicted Prices')]\n",
    "        ax.legend(handles=legend_elements)\n",
    "        ax.grid(True)\n",
    "        \n",
    "    def predict(self, input_values: Union[pd.Series, np.array], input_dates: np.array = None, dtype=Literal['pandas', 'numpy']):\n",
    "        \"\"\" Predict prices on new values. \"\"\"\n",
    "        try:\n",
    "            input_dates = np.array(input_values.index, dtype=np.datetime64) if input_dates is None else input_dates\n",
    "        except AttributeError:\n",
    "            raise ValueError(\"Either provide input_values pd.Series with DatetimeIndex or input_dates np.array with dates as separate parameter!\")\n",
    "        input_values = np.array(input_values, dtype=np.float32)\n",
    "            \n",
    "        # normalise input:\n",
    "        normalised_input = np.array(self.normaliser.transform(input_values), dtype=np.float64)\n",
    "            \n",
    "        # convert to required shape (batch_size, sequence_length, features)\n",
    "        lstm_input_tensor = torch.unsqueeze(torch.Tensor(normalised_input), 0)\n",
    "        assert lstm_input_tensor.size()[1] == self.rolling_window_size, \"Prediction input needs to be of shape (n_inputs, rolling_window_size, 1)\"\n",
    "        \n",
    "        # call model and re-transform input:\n",
    "        predictions = self.lstm_model(lstm_input_tensor)\n",
    "        predictions = predictions.cpu().detach().numpy()\n",
    "        predictions = np.squeeze(self._normaliser.inverse_transform(predictions))\n",
    "        prediction_dates = pd.date_range(input_dates.max()+pd.Timedelta(f'{self.sampling_rate_minutes}min'), input_dates.max()+ self.forecast_horizon * pd.Timedelta(f'{self.sampling_rate_minutes}min'),\n",
    "                                         freq=f\"{self.sampling_rate_minutes}min\")\n",
    "        \n",
    "        if self.verbose:\n",
    "            input_dates = pd.to_datetime(input_dates)\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "            ax.plot(input_dates, input_values, color='blue', label='Input Prices')\n",
    "            ax.plot(prediction_dates, predictions, color='red', label='Predicted Prices')\n",
    "            tendency = 'UP' if (predictions[-1] > input_values[-1]) else 'DOWN'\n",
    "            print(f'Prices are expected to go {tendency}!')\n",
    "            # formatting:\n",
    "            ax.set_xlabel('Date')\n",
    "            ax.set_ylabel('Price')\n",
    "            ax.set_title('Prediction Overview')\n",
    "            ax.legend()\n",
    "        \n",
    "        if dtype == 'pandas':\n",
    "            return pd.Series(index=prediction_dates, data=predictions)\n",
    "        else:\n",
    "            return predictions, prediction_dates"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Parametrisation",
   "id": "b3cf7ea861098775"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### hidden layer size 64 (a)",
   "id": "e15f8ae815f3f831"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predictor_a2_a2x = LSTMPredictor(sampling_rate_minutes=15,\n",
    "                               price_csv_path=INTERPOLATED_PRICES / \"2025-05-19 23_13_53  DAX Close Interpolated Prices at 15min from 2016-07-01 to 2025-04-30.csv\",\n",
    "                               daily_prediction_hour=16,\n",
    "                               rolling_window_size=32,\n",
    "                               forecast_horizon=16,\n",
    "                               # CHANGING PARAMETERS:\n",
    "                               hidden_lstm_layer_size=64,\n",
    "                               n_lstm_layers=2,\n",
    "                               forecast_step_loss_weight_range=(1, .7),  # slowly_decreasing, new default\n",
    "                               # :END\n",
    "                               use_pre_lstm_fc_layer=True,\n",
    "                               use_final_hidden_state=False,\n",
    "                               batch_size=64,\n",
    "                               n_train_epochs=300,\n",
    "                               early_stopping_patience=40,\n",
    "                               model_save_directory=SAVED_MODELS)\n",
    "predictor_a2_a2x"
   ],
   "id": "ec760ee7e034817b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictor_a2_a2y = LSTMPredictor(sampling_rate_minutes=15,\n",
    "                               price_csv_path=INTERPOLATED_PRICES / \"2025-05-19 23_13_53  DAX Close Interpolated Prices at 15min from 2016-07-01 to 2025-04-30.csv\",\n",
    "                               daily_prediction_hour=16,\n",
    "                               rolling_window_size=32,\n",
    "                               forecast_horizon=16,\n",
    "                               # CHANGING PARAMETERS:\n",
    "                               hidden_lstm_layer_size=64,\n",
    "                               n_lstm_layers=2,\n",
    "                               forecast_step_loss_weight_range=(1, .9),  # slowly_decreasing, new default\n",
    "                               # :END\n",
    "                               use_pre_lstm_fc_layer=True,\n",
    "                               use_final_hidden_state=False,\n",
    "                               batch_size=64,\n",
    "                               n_train_epochs=300,\n",
    "                               early_stopping_patience=40,\n",
    "                               model_save_directory=SAVED_MODELS)\n",
    "predictor_a2_a2y"
   ],
   "id": "b8bfc9eb224c7a66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictor_a2_a2z = LSTMPredictor(sampling_rate_minutes=15,\n",
    "                               price_csv_path=INTERPOLATED_PRICES / \"2025-05-19 23_13_53  DAX Close Interpolated Prices at 15min from 2016-07-01 to 2025-04-30.csv\",\n",
    "                               daily_prediction_hour=16,\n",
    "                               rolling_window_size=32,\n",
    "                               forecast_horizon=16,\n",
    "                               # CHANGING PARAMETERS:\n",
    "                               hidden_lstm_layer_size=64,\n",
    "                               n_lstm_layers=2,\n",
    "                               forecast_step_loss_weight_range=(1, 1.2),  # slowly_decreasing, new default\n",
    "                               # :END\n",
    "                               use_pre_lstm_fc_layer=True,\n",
    "                               use_final_hidden_state=False,\n",
    "                               batch_size=64,\n",
    "                               n_train_epochs=300,\n",
    "                               early_stopping_patience=40,\n",
    "                               model_save_directory=SAVED_MODELS)\n",
    "predictor_a2_a2z"
   ],
   "id": "1bb1293d351d6dc1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictor_a2_a3x = LSTMPredictor(sampling_rate_minutes=15,\n",
    "                               price_csv_path=INTERPOLATED_PRICES / \"2025-05-19 23_13_53  DAX Close Interpolated Prices at 15min from 2016-07-01 to 2025-04-30.csv\",\n",
    "                               daily_prediction_hour=16,\n",
    "                               rolling_window_size=32,\n",
    "                               forecast_horizon=16,\n",
    "                               # CHANGING PARAMETERS:\n",
    "                               hidden_lstm_layer_size=64,\n",
    "                               n_lstm_layers=3,\n",
    "                               forecast_step_loss_weight_range=(1, .7),  # slowly_decreasing, new default\n",
    "                               # :END\n",
    "                               use_pre_lstm_fc_layer=True,\n",
    "                               use_final_hidden_state=False,\n",
    "                               batch_size=64,\n",
    "                               n_train_epochs=300,\n",
    "                               early_stopping_patience=40,\n",
    "                               model_save_directory=SAVED_MODELS)\n",
    "predictor_a2_a3x"
   ],
   "id": "c410eabc5ca602e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictor_a2_a3y = LSTMPredictor(sampling_rate_minutes=15,\n",
    "                               price_csv_path=INTERPOLATED_PRICES / \"2025-05-19 23_13_53  DAX Close Interpolated Prices at 15min from 2016-07-01 to 2025-04-30.csv\",\n",
    "                               daily_prediction_hour=16,\n",
    "                               rolling_window_size=32,\n",
    "                               forecast_horizon=16,\n",
    "                               # CHANGING PARAMETERS:\n",
    "                               hidden_lstm_layer_size=64,\n",
    "                               n_lstm_layers=3,\n",
    "                               forecast_step_loss_weight_range=(1, .9),  # slowly_decreasing, new default\n",
    "                               # :END\n",
    "                               use_pre_lstm_fc_layer=True,\n",
    "                               use_final_hidden_state=False,\n",
    "                               batch_size=64,\n",
    "                               n_train_epochs=300,\n",
    "                               early_stopping_patience=40,\n",
    "                               model_save_directory=SAVED_MODELS)\n",
    "predictor_a2_a3y"
   ],
   "id": "8078924a893d47ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictor_a2_a3z = LSTMPredictor(sampling_rate_minutes=15,\n",
    "                               price_csv_path=INTERPOLATED_PRICES / \"2025-05-19 23_13_53  DAX Close Interpolated Prices at 15min from 2016-07-01 to 2025-04-30.csv\",\n",
    "                               daily_prediction_hour=16,\n",
    "                               rolling_window_size=32,\n",
    "                               forecast_horizon=16,\n",
    "                               # CHANGING PARAMETERS:\n",
    "                               hidden_lstm_layer_size=64,\n",
    "                               n_lstm_layers=3,\n",
    "                               forecast_step_loss_weight_range=(1, 1.2),  # slowly_decreasing, new default\n",
    "                               # :END\n",
    "                               use_pre_lstm_fc_layer=True,\n",
    "                               use_final_hidden_state=False,\n",
    "                               batch_size=64,\n",
    "                               n_train_epochs=300,\n",
    "                               early_stopping_patience=40,\n",
    "                               model_save_directory=SAVED_MODELS)\n",
    "predictor_a2_a3z"
   ],
   "id": "26cbacbf762de814"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### hidden layer size 128 (b)",
   "id": "7cd53edbc58a7b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictor_a2_b2x = LSTMPredictor(sampling_rate_minutes=15,\n",
    "                                 price_csv_path=INTERPOLATED_PRICES / \"2025-05-19 23_13_53  DAX Close Interpolated Prices at 15min from 2016-07-01 to 2025-04-30.csv\",\n",
    "                                 daily_prediction_hour=16,\n",
    "                                 rolling_window_size=32,\n",
    "                                 forecast_horizon=16,\n",
    "                                 # CHANGING PARAMETERS:\n",
    "                                 hidden_lstm_layer_size=128,\n",
    "                                 n_lstm_layers=2,\n",
    "                                 forecast_step_loss_weight_range=(1, .7),  # slowly_decreasing, new default\n",
    "                                 # :END\n",
    "                                 use_pre_lstm_fc_layer=True,\n",
    "                                 use_final_hidden_state=False,\n",
    "                                 batch_size=64,\n",
    "                                 n_train_epochs=300,\n",
    "                                 early_stopping_patience=40,\n",
    "                                 model_save_directory=SAVED_MODELS)\n",
    "predictor_a2_b2x"
   ],
   "id": "102a5db63cefeb14"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictor_a2_b2y = LSTMPredictor(sampling_rate_minutes=15,\n",
    "                                 price_csv_path=INTERPOLATED_PRICES / \"2025-05-19 23_13_53  DAX Close Interpolated Prices at 15min from 2016-07-01 to 2025-04-30.csv\",\n",
    "                                 daily_prediction_hour=16,\n",
    "                                 rolling_window_size=32,\n",
    "                                 forecast_horizon=16,\n",
    "                                 # CHANGING PARAMETERS:\n",
    "                                 hidden_lstm_layer_size=128,\n",
    "                                 n_lstm_layers=2,\n",
    "                                 forecast_step_loss_weight_range=(1, .9),  # slowly_decreasing, new default\n",
    "                                 # :END\n",
    "                                 use_pre_lstm_fc_layer=True,\n",
    "                                 use_final_hidden_state=False,\n",
    "                                 batch_size=64,\n",
    "                                 n_train_epochs=300,\n",
    "                                 early_stopping_patience=40,\n",
    "                                 model_save_directory=SAVED_MODELS)\n",
    "predictor_a2_b2y"
   ],
   "id": "24762ebf8582bfc9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictor_a2_b2z = LSTMPredictor(sampling_rate_minutes=15,\n",
    "                                 price_csv_path=INTERPOLATED_PRICES / \"2025-05-19 23_13_53  DAX Close Interpolated Prices at 15min from 2016-07-01 to 2025-04-30.csv\",\n",
    "                                 daily_prediction_hour=16,\n",
    "                                 rolling_window_size=32,\n",
    "                                 forecast_horizon=16,\n",
    "                                 # CHANGING PARAMETERS:\n",
    "                                 hidden_lstm_layer_size=128,\n",
    "                                 n_lstm_layers=2,\n",
    "                                 forecast_step_loss_weight_range=(1, 1.2),  # slowly_decreasing, new default\n",
    "                                 # :END\n",
    "                                 use_pre_lstm_fc_layer=True,\n",
    "                                 use_final_hidden_state=False,\n",
    "                                 batch_size=64,\n",
    "                                 n_train_epochs=300,\n",
    "                                 early_stopping_patience=40,\n",
    "                                 model_save_directory=SAVED_MODELS)\n",
    "predictor_a2_b2z"
   ],
   "id": "76802a4108e78c2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictor_a2_b3x = LSTMPredictor(sampling_rate_minutes=15,\n",
    "                                 price_csv_path=INTERPOLATED_PRICES / \"2025-05-19 23_13_53  DAX Close Interpolated Prices at 15min from 2016-07-01 to 2025-04-30.csv\",\n",
    "                                 daily_prediction_hour=16,\n",
    "                                 rolling_window_size=32,\n",
    "                                 forecast_horizon=16,\n",
    "                                 # CHANGING PARAMETERS:\n",
    "                                 hidden_lstm_layer_size=128,\n",
    "                                 n_lstm_layers=3,\n",
    "                                 forecast_step_loss_weight_range=(1, .7),  # slowly_decreasing, new default\n",
    "                                 # :END\n",
    "                                 use_pre_lstm_fc_layer=True,\n",
    "                                 use_final_hidden_state=False,\n",
    "                                 batch_size=64,\n",
    "                                 n_train_epochs=300,\n",
    "                                 early_stopping_patience=40,\n",
    "                                 model_save_directory=SAVED_MODELS)\n",
    "predictor_a2_b3x"
   ],
   "id": "588225b44a877702"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictor_a2_b3y = LSTMPredictor(sampling_rate_minutes=15,\n",
    "                                 price_csv_path=INTERPOLATED_PRICES / \"2025-05-19 23_13_53  DAX Close Interpolated Prices at 15min from 2016-07-01 to 2025-04-30.csv\",\n",
    "                                 daily_prediction_hour=16,\n",
    "                                 rolling_window_size=32,\n",
    "                                 forecast_horizon=16,\n",
    "                                 # CHANGING PARAMETERS:\n",
    "                                 hidden_lstm_layer_size=128,\n",
    "                                 n_lstm_layers=3,\n",
    "                                 forecast_step_loss_weight_range=(1, .9),  # slowly_decreasing, new default\n",
    "                                 # :END\n",
    "                                 use_pre_lstm_fc_layer=True,\n",
    "                                 use_final_hidden_state=False,\n",
    "                                 batch_size=64,\n",
    "                                 n_train_epochs=300,\n",
    "                                 early_stopping_patience=40,\n",
    "                                 model_save_directory=SAVED_MODELS)\n",
    "predictor_a2_b3y"
   ],
   "id": "b5c8f7772188fc63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictor_a2_b3z = LSTMPredictor(sampling_rate_minutes=15,\n",
    "                                 price_csv_path=INTERPOLATED_PRICES / \"2025-05-19 23_13_53  DAX Close Interpolated Prices at 15min from 2016-07-01 to 2025-04-30.csv\",\n",
    "                                 daily_prediction_hour=16,\n",
    "                                 rolling_window_size=32,\n",
    "                                 forecast_horizon=16,\n",
    "                                 # CHANGING PARAMETERS:\n",
    "                                 hidden_lstm_layer_size=128,\n",
    "                                 n_lstm_layers=3,\n",
    "                                 forecast_step_loss_weight_range=(1, 1.2),  # slowly_decreasing, new default\n",
    "                                 # :END\n",
    "                                 use_pre_lstm_fc_layer=True,\n",
    "                                 use_final_hidden_state=False,\n",
    "                                 batch_size=64,\n",
    "                                 n_train_epochs=300,\n",
    "                                 early_stopping_patience=40,\n",
    "                                 model_save_directory=SAVED_MODELS)\n",
    "predictor_a2_b3z"
   ],
   "id": "fa411b2c96abeca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### hidden layer size 256 (c)",
   "id": "a0b112c1307cfbe9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictor_a2_c2x = LSTMPredictor(sampling_rate_minutes=15,\n",
    "                                 price_csv_path=INTERPOLATED_PRICES / \"2025-05-19 23_13_53  DAX Close Interpolated Prices at 15min from 2016-07-01 to 2025-04-30.csv\",\n",
    "                                 daily_prediction_hour=16,\n",
    "                                 rolling_window_size=32,\n",
    "                                 forecast_horizon=16,\n",
    "                                 # CHANGING PARAMETERS:\n",
    "                                 hidden_lstm_layer_size=256,\n",
    "                                 n_lstm_layers=2,\n",
    "                                 forecast_step_loss_weight_range=(1, .7),  # slowly_decreasing, new default\n",
    "                                 # :END\n",
    "                                 use_pre_lstm_fc_layer=True,\n",
    "                                 use_final_hidden_state=False,\n",
    "                                 batch_size=64,\n",
    "                                 n_train_epochs=300,\n",
    "                                 early_stopping_patience=40,\n",
    "                                 model_save_directory=SAVED_MODELS)\n",
    "predictor_a2_c2x"
   ],
   "id": "dc4b8f80ac1bd60"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictor_a2_c2y = LSTMPredictor(sampling_rate_minutes=15,\n",
    "                                 price_csv_path=INTERPOLATED_PRICES / \"2025-05-19 23_13_53  DAX Close Interpolated Prices at 15min from 2016-07-01 to 2025-04-30.csv\",\n",
    "                                 daily_prediction_hour=16,\n",
    "                                 rolling_window_size=32,\n",
    "                                 forecast_horizon=16,\n",
    "                                 # CHANGING PARAMETERS:\n",
    "                                 hidden_lstm_layer_size=256,\n",
    "                                 n_lstm_layers=2,\n",
    "                                 forecast_step_loss_weight_range=(1, .9),  # slowly_decreasing, new default\n",
    "                                 # :END\n",
    "                                 use_pre_lstm_fc_layer=True,\n",
    "                                 use_final_hidden_state=False,\n",
    "                                 batch_size=64,\n",
    "                                 n_train_epochs=300,\n",
    "                                 early_stopping_patience=40,\n",
    "                                 model_save_directory=SAVED_MODELS)\n",
    "predictor_a2_c2y"
   ],
   "id": "f67a3c14ba506906"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictor_a2_c2z = LSTMPredictor(sampling_rate_minutes=15,\n",
    "                                 price_csv_path=INTERPOLATED_PRICES / \"2025-05-19 23_13_53  DAX Close Interpolated Prices at 15min from 2016-07-01 to 2025-04-30.csv\",\n",
    "                                 daily_prediction_hour=16,\n",
    "                                 rolling_window_size=32,\n",
    "                                 forecast_horizon=16,\n",
    "                                 # CHANGING PARAMETERS:\n",
    "                                 hidden_lstm_layer_size=256,\n",
    "                                 n_lstm_layers=2,\n",
    "                                 forecast_step_loss_weight_range=(1, 1.2),  # slowly_decreasing, new default\n",
    "                                 # :END\n",
    "                                 use_pre_lstm_fc_layer=True,\n",
    "                                 use_final_hidden_state=False,\n",
    "                                 batch_size=64,\n",
    "                                 n_train_epochs=300,\n",
    "                                 early_stopping_patience=40,\n",
    "                                 model_save_directory=SAVED_MODELS)\n",
    "predictor_a2_c2z"
   ],
   "id": "da3e0be8098c7806"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictor_a2_c3x = LSTMPredictor(sampling_rate_minutes=15,\n",
    "                                 price_csv_path=INTERPOLATED_PRICES / \"2025-05-19 23_13_53  DAX Close Interpolated Prices at 15min from 2016-07-01 to 2025-04-30.csv\",\n",
    "                                 daily_prediction_hour=16,\n",
    "                                 rolling_window_size=32,\n",
    "                                 forecast_horizon=16,\n",
    "                                 # CHANGING PARAMETERS:\n",
    "                                 hidden_lstm_layer_size=256,\n",
    "                                 n_lstm_layers=3,\n",
    "                                 forecast_step_loss_weight_range=(1, .7),  # slowly_decreasing, new default\n",
    "                                 # :END\n",
    "                                 use_pre_lstm_fc_layer=True,\n",
    "                                 use_final_hidden_state=False,\n",
    "                                 batch_size=64,\n",
    "                                 n_train_epochs=300,\n",
    "                                 early_stopping_patience=40,\n",
    "                                 model_save_directory=SAVED_MODELS)\n",
    "predictor_a2_c3x"
   ],
   "id": "180c7339d0c861af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictor_a2_c3y = LSTMPredictor(sampling_rate_minutes=15,\n",
    "                                 price_csv_path=INTERPOLATED_PRICES / \"2025-05-19 23_13_53  DAX Close Interpolated Prices at 15min from 2016-07-01 to 2025-04-30.csv\",\n",
    "                                 daily_prediction_hour=16,\n",
    "                                 rolling_window_size=32,\n",
    "                                 forecast_horizon=16,\n",
    "                                 # CHANGING PARAMETERS:\n",
    "                                 hidden_lstm_layer_size=256,\n",
    "                                 n_lstm_layers=3,\n",
    "                                 forecast_step_loss_weight_range=(1, .9),  # slowly_decreasing, new default\n",
    "                                 # :END\n",
    "                                 use_pre_lstm_fc_layer=True,\n",
    "                                 use_final_hidden_state=False,\n",
    "                                 batch_size=64,\n",
    "                                 n_train_epochs=300,\n",
    "                                 early_stopping_patience=40,\n",
    "                                 model_save_directory=SAVED_MODELS)\n",
    "predictor_a2_c3y"
   ],
   "id": "219556903ee10a31"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictor_a2_c3z = LSTMPredictor(sampling_rate_minutes=15,\n",
    "                                 price_csv_path=INTERPOLATED_PRICES / \"2025-05-19 23_13_53  DAX Close Interpolated Prices at 15min from 2016-07-01 to 2025-04-30.csv\",\n",
    "                                 daily_prediction_hour=16,\n",
    "                                 rolling_window_size=32,\n",
    "                                 forecast_horizon=16,\n",
    "                                 # CHANGING PARAMETERS:\n",
    "                                 hidden_lstm_layer_size=256,\n",
    "                                 n_lstm_layers=3,\n",
    "                                 forecast_step_loss_weight_range=(1, 1.2),  # slowly_decreasing, new default\n",
    "                                 # :END\n",
    "                                 use_pre_lstm_fc_layer=True,\n",
    "                                 use_final_hidden_state=False,\n",
    "                                 batch_size=64,\n",
    "                                 n_train_epochs=300,\n",
    "                                 early_stopping_patience=40,\n",
    "                                 model_save_directory=SAVED_MODELS)\n",
    "predictor_a2_c3z"
   ],
   "id": "bfcc093a8dfbffe6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b6df9a00e4a74dab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d4d1cc0d0b8d0f2f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run",
   "id": "dced0343fd4bcec6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T22:04:38.269968Z",
     "start_time": "2025-05-19T22:04:38.266897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "AV_API_KEY_FILE = ROOT / \"private\" / \"Alpha Vantage API Key.txt\"\n",
    "with open(AV_API_KEY_FILE) as file: AV_API_KEY = file.read()\n",
    "\n",
    "sampling_rate_minutes = 15\n",
    "ticker = 'Dax'"
   ],
   "id": "1eb48888dd32c323",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T22:04:39.236887Z",
     "start_time": "2025-05-19T22:04:38.573825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ts = TimeSeries(key=AV_API_KEY, output_format='pandas')\n",
    "recent_dax = ts.get_intraday(ticker, interval=f'{sampling_rate_minutes}min', outputsize=\"compact\" if 14*60/sampling_rate_minutes < 100 else \"full\")\n",
    "daily_dax = recent_dax[0][recent_dax[0].index.day_of_year == recent_dax[0].index.day_of_year.max()]['4. close']  # last day\n",
    "recent_price_data = prep.time_interpolation_new_sampling_rate(daily_dax, '4. close', 'date', f'{sampling_rate_minutes}min', manual_operating_hours=(8, 22))\n",
    "recent_price_data"
   ],
   "id": "ce61a1509840068d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        close\n",
       "date                         \n",
       "2025-05-16 08:00:00  43.48750\n",
       "2025-05-16 08:15:00  43.24000\n",
       "2025-05-16 08:30:00  42.92000\n",
       "2025-05-16 08:45:00  42.84000\n",
       "2025-05-16 09:00:00  42.76000\n",
       "2025-05-16 09:15:00  42.78000\n",
       "2025-05-16 09:30:00  42.80000\n",
       "2025-05-16 09:45:00  42.87500\n",
       "2025-05-16 10:00:00  42.89790\n",
       "2025-05-16 10:15:00  42.85000\n",
       "2025-05-16 10:30:00  42.61010\n",
       "2025-05-16 10:45:00  42.70000\n",
       "2025-05-16 11:00:00  42.71000\n",
       "2025-05-16 11:15:00  42.75250\n",
       "2025-05-16 11:30:00  42.79500\n",
       "2025-05-16 11:45:00  42.79490\n",
       "2025-05-16 12:00:00  42.71810\n",
       "2025-05-16 12:15:00  42.76500\n",
       "2025-05-16 12:30:00  42.76000\n",
       "2025-05-16 12:45:00  42.76000\n",
       "2025-05-16 13:00:00  42.85000\n",
       "2025-05-16 13:15:00  42.84500\n",
       "2025-05-16 13:30:00  42.80000\n",
       "2025-05-16 13:45:00  42.86670\n",
       "2025-05-16 14:00:00  42.82000\n",
       "2025-05-16 14:15:00  42.84000\n",
       "2025-05-16 14:30:00  42.89000\n",
       "2025-05-16 14:45:00  42.87400\n",
       "2025-05-16 15:00:00  42.85000\n",
       "2025-05-16 15:15:00  42.86760\n",
       "2025-05-16 15:30:00  42.84450\n",
       "2025-05-16 15:45:00  42.90000\n",
       "2025-05-16 16:00:00  42.50000\n",
       "2025-05-16 16:15:00  43.00000\n",
       "2025-05-16 16:30:00  42.99000\n",
       "2025-05-16 16:45:00  42.98000\n",
       "2025-05-16 17:00:00  42.99000\n",
       "2025-05-16 17:15:00  43.00000\n",
       "2025-05-16 17:30:00  43.00000\n",
       "2025-05-16 17:45:00  43.00000\n",
       "2025-05-16 18:00:00  43.00000\n",
       "2025-05-16 18:15:00  43.00000\n",
       "2025-05-16 18:30:00  42.78390\n",
       "2025-05-16 18:45:00  42.80195\n",
       "2025-05-16 19:00:00  42.82000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-05-16 08:00:00</th>\n",
       "      <td>43.48750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 08:15:00</th>\n",
       "      <td>43.24000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 08:30:00</th>\n",
       "      <td>42.92000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 08:45:00</th>\n",
       "      <td>42.84000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 09:00:00</th>\n",
       "      <td>42.76000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 09:15:00</th>\n",
       "      <td>42.78000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 09:30:00</th>\n",
       "      <td>42.80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 09:45:00</th>\n",
       "      <td>42.87500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 10:00:00</th>\n",
       "      <td>42.89790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 10:15:00</th>\n",
       "      <td>42.85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 10:30:00</th>\n",
       "      <td>42.61010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 10:45:00</th>\n",
       "      <td>42.70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 11:00:00</th>\n",
       "      <td>42.71000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 11:15:00</th>\n",
       "      <td>42.75250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 11:30:00</th>\n",
       "      <td>42.79500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 11:45:00</th>\n",
       "      <td>42.79490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 12:00:00</th>\n",
       "      <td>42.71810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 12:15:00</th>\n",
       "      <td>42.76500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 12:30:00</th>\n",
       "      <td>42.76000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 12:45:00</th>\n",
       "      <td>42.76000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 13:00:00</th>\n",
       "      <td>42.85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 13:15:00</th>\n",
       "      <td>42.84500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 13:30:00</th>\n",
       "      <td>42.80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 13:45:00</th>\n",
       "      <td>42.86670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 14:00:00</th>\n",
       "      <td>42.82000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 14:15:00</th>\n",
       "      <td>42.84000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 14:30:00</th>\n",
       "      <td>42.89000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 14:45:00</th>\n",
       "      <td>42.87400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 15:00:00</th>\n",
       "      <td>42.85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 15:15:00</th>\n",
       "      <td>42.86760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 15:30:00</th>\n",
       "      <td>42.84450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 15:45:00</th>\n",
       "      <td>42.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 16:00:00</th>\n",
       "      <td>42.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 16:15:00</th>\n",
       "      <td>43.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 16:30:00</th>\n",
       "      <td>42.99000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 16:45:00</th>\n",
       "      <td>42.98000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 17:00:00</th>\n",
       "      <td>42.99000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 17:15:00</th>\n",
       "      <td>43.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 17:30:00</th>\n",
       "      <td>43.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 17:45:00</th>\n",
       "      <td>43.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 18:00:00</th>\n",
       "      <td>43.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 18:15:00</th>\n",
       "      <td>43.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 18:30:00</th>\n",
       "      <td>42.78390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 18:45:00</th>\n",
       "      <td>42.80195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 19:00:00</th>\n",
       "      <td>42.82000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T22:04:40.252617Z",
     "start_time": "2025-05-19T22:04:40.008818Z"
    }
   },
   "cell_type": "code",
   "source": "predictor_a2_1.predict(recent_price_data.iloc[:32])",
   "id": "b2b3d71f016ff318",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prices are expected to go DOWN!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([31.8091462 , 31.8301834 , 31.85673586, 31.88494352, 31.91238934,\n",
       "        31.93949301, 31.96582016, 31.99007451, 32.01100482, 32.02798444,\n",
       "        32.04102383, 32.05052384, 32.05705088, 32.06117972, 32.06342963,\n",
       "        32.06423025]),\n",
       " DatetimeIndex(['2025-05-16 16:00:00', '2025-05-16 16:15:00',\n",
       "                '2025-05-16 16:30:00', '2025-05-16 16:45:00',\n",
       "                '2025-05-16 17:00:00', '2025-05-16 17:15:00',\n",
       "                '2025-05-16 17:30:00', '2025-05-16 17:45:00',\n",
       "                '2025-05-16 18:00:00', '2025-05-16 18:15:00',\n",
       "                '2025-05-16 18:30:00', '2025-05-16 18:45:00',\n",
       "                '2025-05-16 19:00:00', '2025-05-16 19:15:00',\n",
       "                '2025-05-16 19:30:00', '2025-05-16 19:45:00'],\n",
       "               dtype='datetime64[ns]', freq='15min'))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "565aa1f84953ed03"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
