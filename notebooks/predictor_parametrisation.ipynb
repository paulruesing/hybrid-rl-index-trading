{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Price Predictor Parameter Optimisation",
   "id": "71b6501c476a85d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T21:09:51.840267Z",
     "start_time": "2025-06-23T21:09:47.609760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import src.utils.file_management as filemgmt\n",
    "import src.pipeline.preprocessing as prep\n",
    "import src.pipeline.predictors as predictors\n",
    "from src.pipeline.predictors import LSTMPredictor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Literal, Union\n",
    "\n",
    "from tqdm import tqdm\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "ec348715c8a0ff56",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T21:12:16.372054Z",
     "start_time": "2025-06-23T21:12:16.369043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ROOT = Path().resolve().parent\n",
    "\n",
    "DATA = ROOT / \"data\"\n",
    "DAILY_PRICES = DATA / \"daily_price_downloads\"\n",
    "MINUTELY_PRICES = DATA / \"minutely_price_downloads\"\n",
    "#INTERPOLATED_PRICES = DATA / \"interpolated_prices\"\n",
    "INTERPOLATED_SMOOTHED_PRICES = DATA / \"interpolated_smoothed_prices\"\n",
    "\n",
    "SAVED_MODELS = DATA / \"saved_models\" / \"smoothed_data\""
   ],
   "id": "e487f3895fe5c86e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parametrisation Short-Term - a2\n",
    "Predict **4 hours** based on **15-minutely price data** of the **last 8 hours**."
   ],
   "id": "afff8d2ce08e1d5a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T06:38:27.622147Z",
     "start_time": "2025-06-24T06:13:08.296975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a2_results = predictors.predictor_parametrisation_loop(evaluate_hit_rate=True,\n",
    "                                                       sort_metric='Val HR',\n",
    "                                                       n_train_epochs=200,\n",
    "                                                       early_stopping_patience=20,\n",
    "                                                       sampling_rate_minutes=15,  # 15 minutes\n",
    "                                                       price_csv_path=filemgmt.most_recent_file(INTERPOLATED_SMOOTHED_PRICES, '.csv', 'at 15min'),\n",
    "                                                       daily_prediction_hour=16,\n",
    "                                                       predict_before_daily_prediction_hour=False,\n",
    "                                                       rolling_window_size=32,\n",
    "                                                       forecast_horizon=16,\n",
    "                                                       batch_size=64,\n",
    "                                                       validation_split=0.1,\n",
    "                                                       model_save_directory=SAVED_MODELS / \"predictor_a2\",\n",
    "                                                       # parameters to optimise for:\n",
    "                                                       hidden_lstm_layer_size_set=[128, 256],  # 64 (was mostly worse)\n",
    "                                                       n_lstm_layers_set=[3, 4],  # 2 (was mostly worse)\n",
    "                                                       forecast_step_loss_weight_range_set=[(1, .7), (.85, .85),\n",
    "                                                                                            (.7, 1)],\n",
    "                                                       use_pre_lstm_fc_layer_set=[False],  # True (maybe simplicity is key?)\n",
    "                                                       use_final_hidden_state_set=[True],  # False  (settings seems to have negligible impact)\n",
    "                                                       dropout_set=[.4],  # .3  (.4 seems to generalise better, as expected)\n",
    "                                                       )\n",
    "a2_results"
   ],
   "id": "23ec0590be3c0fc5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2769 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.03634208848234266 | Val Loss: 4.145623028278351  | Patience 19/20 | LRate: 0.000125 | Progress:  14%|█▎        | 27/200 [02:07<13:38,  4.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 4.186663746833801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2492/2492 [00:26<00:00, 93.52it/s] \n",
      "100%|██████████| 277/277 [00:02<00:00, 94.52it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2769 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.03844825329724699 | Val Loss: 3.867366850376129  | Patience 19/20 | LRate: 0.000125 | Progress:  13%|█▎        | 26/200 [02:01<13:32,  4.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 3.5546432435512543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2492/2492 [00:25<00:00, 99.17it/s] \n",
      "100%|██████████| 277/277 [00:02<00:00, 99.40it/s] \n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2769 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.028598237433470786 | Val Loss: 3.057016760110855  | Patience 19/20 | LRate: 9.765625e-07 | Progress:  52%|█████▎    | 105/200 [07:41<06:57,  4.40s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 3.077138364315033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2492/2492 [00:25<00:00, 95.97it/s] \n",
      "100%|██████████| 277/277 [00:02<00:00, 98.35it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2769 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.036450627143494785 | Val Loss: 4.307117402553558  | Patience 19/20 | LRate: 0.000125 | Progress:  12%|█▏        | 24/200 [02:35<19:00,  6.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 3.797271877527237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2492/2492 [00:31<00:00, 78.95it/s]\n",
      "100%|██████████| 277/277 [00:03<00:00, 78.03it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2769 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.040200681425631046 | Val Loss: 4.068845629692078  | Patience 19/20 | LRate: 0.000125 | Progress:  10%|█         | 21/200 [02:19<19:44,  6.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 3.6798634380102158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2492/2492 [00:32<00:00, 77.52it/s]\n",
      "100%|██████████| 277/277 [00:03<00:00, 78.61it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2769 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.04195999255171046 | Val Loss: 3.564111292362213  | Patience 19/20 | LRate: 0.000125 | Progress:  12%|█▏        | 24/200 [02:37<19:12,  6.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 3.6155418157577515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2492/2492 [00:31<00:00, 79.63it/s]\n",
      "100%|██████████| 277/277 [00:03<00:00, 86.58it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2769 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.05233658803626895 | Val Loss: 4.020478963851929  | Patience 5/20 | LRate: 0.0005 | Progress:   7%|▋         | 14/200 [02:44<36:25, 11.75s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[16]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m a2_results = \u001B[43mpredictors\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredictor_parametrisation_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_hit_rate\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[43m                                                       \u001B[49m\u001B[43msort_metric\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mVal HR\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m                                                       \u001B[49m\u001B[43mn_train_epochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m200\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m                                                       \u001B[49m\u001B[43mearly_stopping_patience\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m20\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m                                                       \u001B[49m\u001B[43msampling_rate_minutes\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m15\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# 15 minutes\u001B[39;49;00m\n\u001B[32m      6\u001B[39m \u001B[43m                                                       \u001B[49m\u001B[43mprice_csv_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfilemgmt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmost_recent_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mINTERPOLATED_SMOOTHED_PRICES\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m.csv\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mat 15min\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m                                                       \u001B[49m\u001B[43mdaily_prediction_hour\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m16\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m                                                       \u001B[49m\u001B[43mpredict_before_daily_prediction_hour\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m                                                       \u001B[49m\u001B[43mrolling_window_size\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m32\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m                                                       \u001B[49m\u001B[43mforecast_horizon\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m16\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m                                                       \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m64\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[43m                                                       \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     13\u001B[39m \u001B[43m                                                       \u001B[49m\u001B[43mmodel_save_directory\u001B[49m\u001B[43m=\u001B[49m\u001B[43mSAVED_MODELS\u001B[49m\u001B[43m \u001B[49m\u001B[43m/\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mpredictor_a2\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m                                                       \u001B[49m\u001B[38;5;66;43;03m# parameters to optimise for:\u001B[39;49;00m\n\u001B[32m     15\u001B[39m \u001B[43m                                                       \u001B[49m\u001B[43mhidden_lstm_layer_size_set\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m128\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m256\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# 64 (was mostly worse)\u001B[39;49;00m\n\u001B[32m     16\u001B[39m \u001B[43m                                                       \u001B[49m\u001B[43mn_lstm_layers_set\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m4\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# 2 (was mostly worse)\u001B[39;49;00m\n\u001B[32m     17\u001B[39m \u001B[43m                                                       \u001B[49m\u001B[43mforecast_step_loss_weight_range_set\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m.7\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m.85\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m.85\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     18\u001B[39m \u001B[43m                                                                                            \u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m.7\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     19\u001B[39m \u001B[43m                                                       \u001B[49m\u001B[43muse_pre_lstm_fc_layer_set\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# True (maybe simplicity is key?)\u001B[39;49;00m\n\u001B[32m     20\u001B[39m \u001B[43m                                                       \u001B[49m\u001B[43muse_final_hidden_state_set\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# False  (settings seems to have negligible impact)\u001B[39;49;00m\n\u001B[32m     21\u001B[39m \u001B[43m                                                       \u001B[49m\u001B[43mdropout_set\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m.4\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# .3  (.4 seems to generalise better, as expected)\u001B[39;49;00m\n\u001B[32m     22\u001B[39m \u001B[43m                                                       \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     23\u001B[39m a2_results\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Mobile Documents/com~apple~CloudDocs/PR iCloud/Work/Personal/Programming/Github Repos/hybrid-rl-index-trading/src/pipeline/predictors.py:261\u001B[39m, in \u001B[36mpredictor_parametrisation_loop\u001B[39m\u001B[34m(hidden_lstm_layer_size_set, n_lstm_layers_set, forecast_step_loss_weight_range_set, use_pre_lstm_fc_layer_set, use_final_hidden_state_set, dropout_set, evaluate_hit_rate, n_train_epochs, early_stopping_patience, sort_metric, **constant_kwargs)\u001B[39m\n\u001B[32m    252\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m evaluate_hit_rate: columns += [\u001B[33m'\u001B[39m\u001B[33mTrain HR\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mVal HR\u001B[39m\u001B[33m'\u001B[39m]\n\u001B[32m    254\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m config_ind, (\n\u001B[32m    255\u001B[39m         hidden_lstm_layer_size, n_lstm_layers, forecast_step_loss_weight_range, use_pre_lstm_fc_layer,\n\u001B[32m    256\u001B[39m         use_final_hidden_state,\n\u001B[32m   (...)\u001B[39m\u001B[32m    259\u001B[39m             use_pre_lstm_fc_layer_set, use_final_hidden_state_set, dropout_set)):\n\u001B[32m    260\u001B[39m     \u001B[38;5;66;03m# initialise and train model:\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m261\u001B[39m     temp_model = \u001B[43mLSTMPredictor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_lstm_layer_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhidden_lstm_layer_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_lstm_layers\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_lstm_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    262\u001B[39m \u001B[43m                               \u001B[49m\u001B[43mforecast_step_loss_weight_range\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforecast_step_loss_weight_range\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    263\u001B[39m \u001B[43m                               \u001B[49m\u001B[43muse_pre_lstm_fc_layer\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_pre_lstm_fc_layer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    264\u001B[39m \u001B[43m                               \u001B[49m\u001B[43muse_final_hidden_state\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_final_hidden_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdropout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    265\u001B[39m \u001B[43m                               \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# to reduce console output\u001B[39;49;00m\n\u001B[32m    266\u001B[39m \u001B[43m                               \u001B[49m\u001B[43mn_train_epochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_train_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    267\u001B[39m \u001B[43m                               \u001B[49m\u001B[38;5;66;43;03m# ensure n_train_epochs specification to trigger training upon initialisation\u001B[39;49;00m\n\u001B[32m    268\u001B[39m \u001B[43m                               \u001B[49m\u001B[43mearly_stopping_patience\u001B[49m\u001B[43m=\u001B[49m\u001B[43mearly_stopping_patience\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    269\u001B[39m \u001B[43m                               \u001B[49m\u001B[43mevaluate_hit_rate_upon_training\u001B[49m\u001B[43m=\u001B[49m\u001B[43mevaluate_hit_rate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    270\u001B[39m \u001B[43m                               \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mconstant_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    272\u001B[39m     \u001B[38;5;66;03m# save settings and model losses:\u001B[39;00m\n\u001B[32m    273\u001B[39m     setting_and_loss_list = [hidden_lstm_layer_size, n_lstm_layers, forecast_step_loss_weight_range,\n\u001B[32m    274\u001B[39m                              use_pre_lstm_fc_layer, use_final_hidden_state, dropout,\n\u001B[32m    275\u001B[39m                              temp_model.loss_train, temp_model.loss_val]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Mobile Documents/com~apple~CloudDocs/PR iCloud/Work/Personal/Programming/Github Repos/hybrid-rl-index-trading/src/pipeline/predictors.py:379\u001B[39m, in \u001B[36mLSTMPredictor.__init__\u001B[39m\u001B[34m(self, sampling_rate_minutes, price_csv_path, price_column, date_column, daily_prediction_hour, predict_before_daily_prediction_hour, rolling_window_size, forecast_horizon, validation_split, batch_size, model_load_file_path, hidden_lstm_layer_size, n_lstm_layers, dropout, use_final_hidden_state, use_pre_lstm_fc_layer, init_weights, use_mps_if_available, model_save_directory, forecast_step_loss_weight_range, n_train_epochs, lr_scheduler, initial_lr, step_scheduler_step_size, plateau_scheduler_factor, early_stopping_patience, verbose, evaluate_hit_rate_upon_training)\u001B[39m\n\u001B[32m    376\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[32m    377\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mNo training epochs defined upon initialisation. Define LSTMPredictor.n_train_epochs to start training procedure.\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m    378\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m n_train_epochs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# automatically start training\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m379\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrun_training\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    380\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m verbose:\n\u001B[32m    381\u001B[39m         \u001B[38;5;28mprint\u001B[39m(\u001B[33m'\u001B[39m\u001B[33mTraining finished. Plotting results for validation split:\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Mobile Documents/com~apple~CloudDocs/PR iCloud/Work/Personal/Programming/Github Repos/hybrid-rl-index-trading/src/pipeline/predictors.py:881\u001B[39m, in \u001B[36mLSTMPredictor.run_training\u001B[39m\u001B[34m(self, custom_n_epochs)\u001B[39m\n\u001B[32m    879\u001B[39m loss_train_history, loss_val_history = [], []\n\u001B[32m    880\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m progress_bar:\n\u001B[32m--> \u001B[39m\u001B[32m881\u001B[39m     loss_train, lr_train = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mlstm_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdataloader_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimiser\u001B[49m\u001B[43m=\u001B[49m\u001B[43moptimiser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    882\u001B[39m \u001B[43m                                                     \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_criterion\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mloss_criterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    883\u001B[39m \u001B[43m                                                     \u001B[49m\u001B[43mis_training\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    884\u001B[39m     loss_val, _ = \u001B[38;5;28mself\u001B[39m.lstm_model.run_epoch(\u001B[38;5;28mself\u001B[39m.dataloader_val, optimiser=optimiser, device=\u001B[38;5;28mself\u001B[39m.device,\n\u001B[32m    885\u001B[39m                                             loss_criterion=\u001B[38;5;28mself\u001B[39m.loss_criterion, is_training=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m    887\u001B[39m     \u001B[38;5;66;03m# scheduler step:\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Mobile Documents/com~apple~CloudDocs/PR iCloud/Work/Personal/Programming/Github Repos/hybrid-rl-index-trading/src/pipeline/predictors.py:196\u001B[39m, in \u001B[36mLSTMModel.run_epoch\u001B[39m\u001B[34m(self, dataloader, optimiser, device, loss_criterion, is_training)\u001B[39m\n\u001B[32m    192\u001B[39m loss = loss_criterion(out.contiguous(),\n\u001B[32m    193\u001B[39m                       y.contiguous())  \u001B[38;5;66;03m# enforces the tensors to be stored in a contiguous memory block\u001B[39;00m\n\u001B[32m    195\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_training:\n\u001B[32m--> \u001B[39m\u001B[32m196\u001B[39m     \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# backpropagation, traverses computational graph in reverse applying the chain rule to compute gradients\u001B[39;00m\n\u001B[32m    197\u001B[39m     optimiser.step()  \u001B[38;5;66;03m# optimise weights\u001B[39;00m\n\u001B[32m    199\u001B[39m epoch_loss += loss.detach().item()  \u001B[38;5;66;03m# without / batchsize because loss is already averaged, detach loss value from computational graph\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/pru_dev2/envs/rl_env/lib/python3.13/site-packages/torch/_tensor.py:626\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    616\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    617\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    618\u001B[39m         Tensor.backward,\n\u001B[32m    619\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    624\u001B[39m         inputs=inputs,\n\u001B[32m    625\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m626\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    627\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    628\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/pru_dev2/envs/rl_env/lib/python3.13/site-packages/torch/autograd/__init__.py:347\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    342\u001B[39m     retain_graph = create_graph\n\u001B[32m    344\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    345\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    346\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m347\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    348\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    349\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    350\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    351\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    352\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    353\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    354\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/pru_dev2/envs/rl_env/lib/python3.13/site-packages/torch/autograd/graph.py:823\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    821\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    822\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m823\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    824\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    825\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    826\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    827\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parametrisation Mid-Term - b1\n",
    "Predict **1 day** based on **hourly price data** of the **last week**."
   ],
   "id": "b3cf7ea861098775"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T00:05:32.950757Z",
     "start_time": "2025-06-23T22:51:15.424536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "b1_results = predictors.predictor_parametrisation_loop(evaluate_hit_rate=True,\n",
    "                                                       sort_metric='Val HR',\n",
    "                                                       n_train_epochs=200,\n",
    "                                                       early_stopping_patience=20,\n",
    "                                                       sampling_rate_minutes=60,  # hourly prices\n",
    "                                                       price_csv_path=filemgmt.most_recent_file(INTERPOLATED_SMOOTHED_PRICES, '.csv', 'at 60min'),\n",
    "                                                       daily_prediction_hour=16,\n",
    "                                                       predict_before_daily_prediction_hour=True,\n",
    "                                                       rolling_window_size=14*4+8,  # 1 week hindsight (4 days a 14 hours and 1 a 8 hours until 16.00)\n",
    "                                                       forecast_horizon=14,\n",
    "                                                       batch_size=64,\n",
    "                                                       validation_split=0.1,\n",
    "                                                       model_save_directory=SAVED_MODELS / \"predictor_b1\",\n",
    "                                                       # parameters to optimise for:\n",
    "                                                       hidden_lstm_layer_size_set=[128, 256],  # 64 (was mostly worse)\n",
    "                                                       n_lstm_layers_set=[3, 4],  # 2 (was mostly worse)\n",
    "                                                       forecast_step_loss_weight_range_set=[(1, .7), (.85, .85),\n",
    "                                                                                            (.7, 1)],\n",
    "                                                       use_pre_lstm_fc_layer_set=[False],  # True (maybe simplicity is key?)\n",
    "                                                       use_final_hidden_state_set=[True],  # False  (settings seems to have negligible impact)\n",
    "                                                       dropout_set=[.4],  # .3  (.4 seems to generalise better, as expected)\n",
    "                                                       )\n",
    "b1_results"
   ],
   "id": "4071ed493e688898",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2764 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.09590099670458585 | Val Loss: 5.008342802524567  | Patience 19/20 | LRate: 0.000125 | Progress:  12%|█▏        | 23/200 [02:27<18:52,  6.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 5.317424714565277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2487/2487 [00:24<00:00, 102.25it/s]\n",
      "100%|██████████| 277/277 [00:02<00:00, 100.13it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2764 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.09433711087331176 | Val Loss: 4.209865510463715  | Patience 19/20 | LRate: 7.8125e-06 | Progress:  27%|██▋       | 54/200 [05:27<14:44,  6.06s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 4.132578730583191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2487/2487 [00:26<00:00, 95.56it/s] \n",
      "100%|██████████| 277/277 [00:02<00:00, 98.06it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2764 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.10400524432770908 | Val Loss: 3.9685437083244324  | Patience 19/20 | LRate: 6.25e-05 | Progress:  16%|█▌        | 31/200 [03:09<17:15,  6.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 4.297987103462219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2487/2487 [00:24<00:00, 101.91it/s]\n",
      "100%|██████████| 277/277 [00:02<00:00, 102.76it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2764 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.10000602109357715 | Val Loss: 3.954395115375519  | Patience 19/20 | LRate: 0.000125 | Progress:  11%|█         | 22/200 [03:19<26:51,  9.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 3.58964741230011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2487/2487 [00:29<00:00, 83.40it/s]\n",
      "100%|██████████| 277/277 [00:03<00:00, 82.80it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2764 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.10028901428449899 | Val Loss: 3.8436952233314514  | Patience 19/20 | LRate: 0.000125 | Progress:  12%|█▏        | 23/200 [03:27<26:33,  9.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 4.200028955936432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2487/2487 [00:30<00:00, 80.63it/s]\n",
      "100%|██████████| 277/277 [00:03<00:00, 80.18it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2764 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1083264909684658 | Val Loss: 3.794697403907776  | Patience 19/20 | LRate: 0.000125 | Progress:  12%|█▏        | 24/200 [03:34<26:14,  8.95s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 4.141034096479416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2487/2487 [00:30<00:00, 80.79it/s]\n",
      "100%|██████████| 277/277 [00:03<00:00, 80.18it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2764 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0915774944005534 | Val Loss: 4.653989374637604  | Patience 19/20 | LRate: 0.000125 | Progress:  14%|█▍        | 28/200 [07:44<47:33, 16.59s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 4.741025149822235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2487/2487 [00:33<00:00, 73.22it/s]\n",
      "100%|██████████| 277/277 [00:03<00:00, 73.81it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2764 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.09952897066250443 | Val Loss: 4.5220271944999695  | Patience 19/20 | LRate: 0.000125 | Progress:  11%|█         | 22/200 [06:08<49:41, 16.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 4.911805212497711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2487/2487 [00:34<00:00, 73.11it/s]\n",
      "100%|██████████| 277/277 [00:04<00:00, 68.08it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2764 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.10189509997144341 | Val Loss: 6.114156484603882  | Patience 19/20 | LRate: 0.000125 | Progress:  12%|█▏        | 23/200 [06:22<49:05, 16.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 5.612504959106445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2487/2487 [00:35<00:00, 70.76it/s]\n",
      "100%|██████████| 277/277 [00:03<00:00, 70.66it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2764 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.09528303646948189 | Val Loss: 4.039205968379974  | Patience 19/20 | LRate: 0.000125 | Progress:  10%|█         | 21/200 [07:58<1:07:54, 22.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 3.841885417699814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2487/2487 [00:46<00:00, 53.03it/s]\n",
      "100%|██████████| 277/277 [00:05<00:00, 54.84it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2764 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0998441691044718 | Val Loss: 4.147518455982208  | Patience 19/20 | LRate: 0.000125 | Progress:  10%|█         | 21/200 [07:54<1:07:20, 22.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 4.24059134721756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2487/2487 [00:47<00:00, 51.96it/s]\n",
      "100%|██████████| 277/277 [00:05<00:00, 52.87it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2764 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.10226625483483076 | Val Loss: 5.693897366523743  | Patience 19/20 | LRate: 0.000125 | Progress:  12%|█▏        | 24/200 [09:05<1:06:41, 22.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 5.646615624427795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2487/2487 [00:47<00:00, 51.93it/s]\n",
      "100%|██████████| 277/277 [00:05<00:00, 51.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Hidden Layer Size N. LSTM Layers Loss Weight Range Pre-LSTM FC Layer  \\\n",
       "7                256              3      (0.85, 0.85)             False   \n",
       "1                128              3      (0.85, 0.85)             False   \n",
       "5                128              4          (0.7, 1)             False   \n",
       "6                256              3          (1, 0.7)             False   \n",
       "0                128              3          (1, 0.7)             False   \n",
       "2                128              3          (0.7, 1)             False   \n",
       "4                128              4      (0.85, 0.85)             False   \n",
       "8                256              3          (0.7, 1)             False   \n",
       "9                256              4          (1, 0.7)             False   \n",
       "3                128              4          (1, 0.7)             False   \n",
       "11               256              4          (0.7, 1)             False   \n",
       "10               256              4      (0.85, 0.85)             False   \n",
       "\n",
       "   Final Hidden State Dropout Train Loss  Val Loss  Train HR    Val HR  \n",
       "7                True     0.4    0.09791  4.911805  0.516285  0.509025  \n",
       "1                True     0.4   0.094887  4.132579  0.498191  0.505415  \n",
       "5                True     0.4   0.108943  4.141034  0.485726  0.505415  \n",
       "6                True     0.4   0.088177  4.741025   0.49417  0.505415  \n",
       "0                True     0.4   0.096117  5.317425  0.492963  0.501805  \n",
       "2                True     0.4   0.105817  4.297987  0.501809  0.501805  \n",
       "4                True     0.4   0.102449  4.200029  0.516285  0.501805  \n",
       "8                True     0.4   0.103012  5.612505   0.49618  0.498195  \n",
       "9                True     0.4   0.094466  3.841885  0.491757  0.498195  \n",
       "3                True     0.4   0.098504  3.589647   0.48452  0.494585  \n",
       "11               True     0.4   0.104099  5.646616  0.499397  0.490975  \n",
       "10               True     0.4   0.100741  4.240591  0.488138  0.487365  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layer Size</th>\n",
       "      <th>N. LSTM Layers</th>\n",
       "      <th>Loss Weight Range</th>\n",
       "      <th>Pre-LSTM FC Layer</th>\n",
       "      <th>Final Hidden State</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Val Loss</th>\n",
       "      <th>Train HR</th>\n",
       "      <th>Val HR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>4.911805</td>\n",
       "      <td>0.516285</td>\n",
       "      <td>0.509025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.094887</td>\n",
       "      <td>4.132579</td>\n",
       "      <td>0.498191</td>\n",
       "      <td>0.505415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.108943</td>\n",
       "      <td>4.141034</td>\n",
       "      <td>0.485726</td>\n",
       "      <td>0.505415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.088177</td>\n",
       "      <td>4.741025</td>\n",
       "      <td>0.49417</td>\n",
       "      <td>0.505415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.096117</td>\n",
       "      <td>5.317425</td>\n",
       "      <td>0.492963</td>\n",
       "      <td>0.501805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.105817</td>\n",
       "      <td>4.297987</td>\n",
       "      <td>0.501809</td>\n",
       "      <td>0.501805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.102449</td>\n",
       "      <td>4.200029</td>\n",
       "      <td>0.516285</td>\n",
       "      <td>0.501805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.103012</td>\n",
       "      <td>5.612505</td>\n",
       "      <td>0.49618</td>\n",
       "      <td>0.498195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.094466</td>\n",
       "      <td>3.841885</td>\n",
       "      <td>0.491757</td>\n",
       "      <td>0.498195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.098504</td>\n",
       "      <td>3.589647</td>\n",
       "      <td>0.48452</td>\n",
       "      <td>0.494585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.104099</td>\n",
       "      <td>5.646616</td>\n",
       "      <td>0.499397</td>\n",
       "      <td>0.490975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.100741</td>\n",
       "      <td>4.240591</td>\n",
       "      <td>0.488138</td>\n",
       "      <td>0.487365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parametrisation Mid-Term - b3\n",
    "Predict **1 week** based on **daily price data** of the **last 2 months**. "
   ],
   "id": "72a7151872847f29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T22:51:15.094736Z",
     "start_time": "2025-06-23T21:32:26.067662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "b3_results = predictors.predictor_parametrisation_loop(evaluate_hit_rate=True,\n",
    "                                                       sort_metric='Val HR',\n",
    "                                                       n_train_epochs=200,\n",
    "                                                       early_stopping_patience=20,\n",
    "                                                       sampling_rate_minutes=60 * 14,  # one day from 8am to 22pm\n",
    "                                                       price_csv_path=filemgmt.most_recent_file(INTERPOLATED_SMOOTHED_PRICES, '.csv', 'at 1d'),\n",
    "                                                       daily_prediction_hour=16,\n",
    "                                                       predict_before_daily_prediction_hour=True,  # irrelevant\n",
    "                                                       rolling_window_size=2*4*5,  # 2 months a 4 weeks a 5 days hindsight\n",
    "                                                       forecast_horizon=5,  # i.e. 1 week á 5 days\n",
    "                                                       batch_size=64,\n",
    "                                                       validation_split=0.1,\n",
    "                                                       model_save_directory=SAVED_MODELS / \"predictor_b3\",\n",
    "                                                       # parameters to optimise for:\n",
    "                                                       hidden_lstm_layer_size_set=[128, 256],  # 64 (was mostly worse)\n",
    "                                                       n_lstm_layers_set=[3, 4],  # 2 (was mostly worse)\n",
    "                                                       forecast_step_loss_weight_range_set=[(1, .7), (.85, .85),\n",
    "                                                                                            (.7, 1)],\n",
    "                                                       use_pre_lstm_fc_layer_set=[False],  # True (maybe simplicity is key?)\n",
    "                                                       use_final_hidden_state_set=[True],  # False  (settings seems to have negligible impact)\n",
    "                                                       dropout_set=[.4],  # .3  (.4 seems to generalise better, as expected)\n",
    "                                                       )\n",
    "b3_results"
   ],
   "id": "bcc83a565a9d8e50",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2726 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.23178177000954747 | Val Loss: 1.9845280647277832  | Patience 19/20 | LRate: 6.25e-05 | Progress:  24%|██▍       | 48/200 [02:43<08:38,  3.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.060401111841202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2453/2453 [00:09<00:00, 245.62it/s]\n",
      "100%|██████████| 273/273 [00:01<00:00, 259.17it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2726 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.22919574892148376 | Val Loss: 1.9960997998714447  | Patience 19/20 | LRate: 3.125e-05 | Progress:  30%|███       | 60/200 [03:12<07:28,  3.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 1.7760909497737885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2453/2453 [00:09<00:00, 254.40it/s]\n",
      "100%|██████████| 273/273 [00:01<00:00, 250.43it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2726 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.24088628962635994 | Val Loss: 2.0077984631061554  | Patience 19/20 | LRate: 6.25e-05 | Progress:  24%|██▎       | 47/200 [02:30<08:09,  3.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 1.8894870281219482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2453/2453 [00:09<00:00, 256.02it/s]\n",
      "100%|██████████| 273/273 [00:01<00:00, 253.05it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2726 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.21400746214203537 | Val Loss: 1.7603096812963486  | Patience 19/20 | LRate: 0.000125 | Progress:  22%|██▏       | 44/200 [03:26<12:11,  4.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 1.6546754613518715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2453/2453 [00:12<00:00, 199.48it/s]\n",
      "100%|██████████| 273/273 [00:01<00:00, 196.11it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2726 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.30048364074900746 | Val Loss: 2.5321421921253204  | Patience 19/20 | LRate: 0.000125 | Progress:  12%|█▏        | 23/200 [01:50<14:09,  4.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.3818145394325256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2453/2453 [00:12<00:00, 201.84it/s]\n",
      "100%|██████████| 273/273 [00:01<00:00, 200.66it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2726 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.2210663789883256 | Val Loss: 1.9434847235679626  | Patience 19/20 | LRate: 3.90625e-06 | Progress:  49%|████▉     | 98/200 [07:32<07:51,  4.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 1.7084141075611115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2453/2453 [00:12<00:00, 200.99it/s]\n",
      "100%|██████████| 273/273 [00:01<00:00, 196.84it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2726 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1956935143098235 | Val Loss: 1.4230476170778275  | Patience 19/20 | LRate: 1.953125e-06 | Progress:  42%|████▏     | 83/200 [11:38<16:24,  8.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 1.5878761410713196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2453/2453 [00:14<00:00, 165.90it/s]\n",
      "100%|██████████| 273/273 [00:01<00:00, 167.84it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2726 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.20636718580499291 | Val Loss: 2.4164777994155884  | Patience 19/20 | LRate: 6.25e-05 | Progress:  22%|██▎       | 45/200 [06:21<21:52,  8.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.304358124732971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2453/2453 [00:14<00:00, 167.49it/s]\n",
      "100%|██████████| 273/273 [00:01<00:00, 169.12it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2726 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.18730250257067382 | Val Loss: 2.8936528265476227  | Patience 19/20 | LRate: 3.125e-05 | Progress:  26%|██▋       | 53/200 [07:21<20:23,  8.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.8605516850948334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2453/2453 [00:14<00:00, 172.01it/s]\n",
      "100%|██████████| 273/273 [00:01<00:00, 172.90it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2726 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1765779152046889 | Val Loss: 2.866682380437851  | Patience 19/20 | LRate: 0.000125 | Progress:  24%|██▍       | 48/200 [09:08<28:55, 11.42s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 3.2405509650707245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2453/2453 [00:21<00:00, 115.51it/s]\n",
      "100%|██████████| 273/273 [00:02<00:00, 124.98it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2726 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.19195822160691023 | Val Loss: 2.6983207762241364  | Patience 19/20 | LRate: 0.000125 | Progress:  22%|██▏       | 43/200 [08:27<30:51, 11.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.3536068499088287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2453/2453 [00:19<00:00, 126.99it/s]\n",
      "100%|██████████| 273/273 [00:02<00:00, 124.96it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 2726 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.19833338167518377 | Val Loss: 2.2712833881378174  | Patience 19/20 | LRate: 1.5625e-05 | Progress:  30%|██▉       | 59/200 [11:27<27:24, 11.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.088192492723465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2453/2453 [00:19<00:00, 124.02it/s]\n",
      "100%|██████████| 273/273 [00:02<00:00, 125.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Hidden Layer Size N. LSTM Layers Loss Weight Range Pre-LSTM FC Layer  \\\n",
       "11               256              4          (0.7, 1)             False   \n",
       "2                128              3          (0.7, 1)             False   \n",
       "3                128              4          (1, 0.7)             False   \n",
       "7                256              3      (0.85, 0.85)             False   \n",
       "8                256              3          (0.7, 1)             False   \n",
       "1                128              3      (0.85, 0.85)             False   \n",
       "9                256              4          (1, 0.7)             False   \n",
       "10               256              4      (0.85, 0.85)             False   \n",
       "0                128              3          (1, 0.7)             False   \n",
       "4                128              4      (0.85, 0.85)             False   \n",
       "5                128              4          (0.7, 1)             False   \n",
       "6                256              3          (1, 0.7)             False   \n",
       "\n",
       "   Final Hidden State Dropout Train Loss  Val Loss  Train HR    Val HR  \n",
       "11               True     0.4   0.199685  2.088192  0.640033  0.571429  \n",
       "2                True     0.4   0.241248  1.889487  0.600489  0.567766  \n",
       "3                True     0.4   0.215941  1.654675  0.601712  0.556777  \n",
       "7                True     0.4   0.206247  2.304358  0.597228  0.553114  \n",
       "8                True     0.4   0.189464  2.860552  0.656339  0.553114  \n",
       "1                True     0.4   0.226236  1.776091  0.599266  0.545788  \n",
       "9                True     0.4   0.173241  3.240551  0.625764  0.545788  \n",
       "10               True     0.4   0.185339  2.353607  0.642071   0.52381  \n",
       "0                True     0.4   0.221777  2.060401  0.572768  0.501832  \n",
       "4                True     0.4   0.291431  2.381815  0.562576  0.498168  \n",
       "5                True     0.4   0.217982  1.708414  0.629433  0.494505  \n",
       "6                True     0.4   0.195321  1.587876  0.622095  0.465201  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layer Size</th>\n",
       "      <th>N. LSTM Layers</th>\n",
       "      <th>Loss Weight Range</th>\n",
       "      <th>Pre-LSTM FC Layer</th>\n",
       "      <th>Final Hidden State</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Val Loss</th>\n",
       "      <th>Train HR</th>\n",
       "      <th>Val HR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.199685</td>\n",
       "      <td>2.088192</td>\n",
       "      <td>0.640033</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.241248</td>\n",
       "      <td>1.889487</td>\n",
       "      <td>0.600489</td>\n",
       "      <td>0.567766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.215941</td>\n",
       "      <td>1.654675</td>\n",
       "      <td>0.601712</td>\n",
       "      <td>0.556777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.206247</td>\n",
       "      <td>2.304358</td>\n",
       "      <td>0.597228</td>\n",
       "      <td>0.553114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.189464</td>\n",
       "      <td>2.860552</td>\n",
       "      <td>0.656339</td>\n",
       "      <td>0.553114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.226236</td>\n",
       "      <td>1.776091</td>\n",
       "      <td>0.599266</td>\n",
       "      <td>0.545788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.173241</td>\n",
       "      <td>3.240551</td>\n",
       "      <td>0.625764</td>\n",
       "      <td>0.545788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.185339</td>\n",
       "      <td>2.353607</td>\n",
       "      <td>0.642071</td>\n",
       "      <td>0.52381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.221777</td>\n",
       "      <td>2.060401</td>\n",
       "      <td>0.572768</td>\n",
       "      <td>0.501832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.291431</td>\n",
       "      <td>2.381815</td>\n",
       "      <td>0.562576</td>\n",
       "      <td>0.498168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.217982</td>\n",
       "      <td>1.708414</td>\n",
       "      <td>0.629433</td>\n",
       "      <td>0.494505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.195321</td>\n",
       "      <td>1.587876</td>\n",
       "      <td>0.622095</td>\n",
       "      <td>0.465201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parametrisation Long-Term - c1\n",
    "Predict **3 weeks** based on **weekly price data** of the **last 6 months**."
   ],
   "id": "bb4de7c18182e5d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T21:32:26.007488Z",
     "start_time": "2025-06-23T21:25:56.733802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "c1_results = predictors.predictor_parametrisation_loop(evaluate_hit_rate=True,\n",
    "                                                       sort_metric='Val HR',\n",
    "                                                       n_train_epochs=200,\n",
    "                                                       early_stopping_patience=20,\n",
    "                                                       sampling_rate_minutes=7 * 14 * 60,  # 1 week = 7 days each from 8am to 22pm\n",
    "                                                       price_csv_path=filemgmt.most_recent_file(INTERPOLATED_SMOOTHED_PRICES, '.csv', 'at 7d'),\n",
    "                                                       daily_prediction_hour=16,\n",
    "                                                       predict_before_daily_prediction_hour=True,  # irrelevant\n",
    "                                                       rolling_window_size=6*4,  # i.e. 6 months á 4 weeks\n",
    "                                                       forecast_horizon=3,  # i.e. 3 weeks\n",
    "                                                       batch_size=64,\n",
    "                                                       validation_split=0.1,\n",
    "                                                       model_save_directory=SAVED_MODELS / \"predictor_c1\",\n",
    "                                                       # parameters to optimise for:\n",
    "                                                       hidden_lstm_layer_size_set=[128, 256],  # 64 (was mostly worse)\n",
    "                                                       n_lstm_layers_set=[3, 4],  # 2 (was mostly worse)\n",
    "                                                       forecast_step_loss_weight_range_set=[(1, .7), (.85, .85),\n",
    "                                                                                            (.7, 1)],\n",
    "                                                       use_pre_lstm_fc_layer_set=[False],  # True (maybe simplicity is key?)\n",
    "                                                       use_final_hidden_state_set=[True],  # False  (settings seems to have negligible impact)\n",
    "                                                       dropout_set=[.4],  # .3  (.4 seems to generalise better, as expected)\n",
    "                                                       )\n",
    "c1_results"
   ],
   "id": "d0cd00960e0703d2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 528 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.13288892526179552 | Val Loss: 0.4664342999458313  | Patience 19/20 | LRate: 6.25e-05 | Progress:  20%|██        | 41/200 [00:16<01:05,  2.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 0.4645077586174011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:01<00:00, 329.95it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 358.26it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 528 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.13020093087106943 | Val Loss: 0.4953591227531433  | Patience 19/20 | LRate: 0.000125 | Progress:  20%|█▉        | 39/200 [00:18<01:15,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 0.5066105127334595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:01<00:00, 354.84it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 416.37it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 528 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.15013970341533422 | Val Loss: 0.4530850648880005  | Patience 19/20 | LRate: 3.125e-05 | Progress:  25%|██▌       | 50/200 [00:21<01:05,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 0.4428817927837372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:01<00:00, 388.19it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 396.91it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 528 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.14519664365798235 | Val Loss: 0.38651105761528015  | Patience 19/20 | LRate: 0.000125 | Progress:  14%|█▎        | 27/200 [00:16<01:48,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 0.37886202335357666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:01<00:00, 317.04it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 279.50it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 528 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.16742044314742088 | Val Loss: 0.4474411606788635  | Patience 19/20 | LRate: 0.000125 | Progress:  15%|█▌        | 30/200 [00:17<01:37,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 0.47264641523361206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:01<00:00, 319.78it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 327.40it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 528 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.17453315015882254 | Val Loss: 0.454120934009552  | Patience 19/20 | LRate: 0.000125 | Progress:  13%|█▎        | 26/200 [00:15<01:42,  1.69it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 0.44557985663414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:01<00:00, 306.40it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 304.65it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 528 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1137954369187355 | Val Loss: 0.4238089323043823  | Patience 19/20 | LRate: 0.000125 | Progress:  16%|█▌        | 31/200 [00:34<03:06,  1.10s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 0.4264664053916931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:01<00:00, 258.90it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 277.99it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 528 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.12554242368787527 | Val Loss: 0.4329126179218292  | Patience 19/20 | LRate: 3.125e-05 | Progress:  24%|██▎       | 47/200 [00:49<02:40,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 0.44285380840301514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:02<00:00, 231.85it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 262.40it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 528 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.10973221994936466 | Val Loss: 0.4815044403076172  | Patience 19/20 | LRate: 0.000125 | Progress:  20%|██        | 41/200 [00:41<02:40,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 0.5012462735176086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:01<00:00, 265.46it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 277.21it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 528 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.13129291031509638 | Val Loss: 0.4490640461444855  | Patience 19/20 | LRate: 0.000125 | Progress:  12%|█▏        | 24/200 [00:33<04:07,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 0.45000597834587097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:02<00:00, 198.00it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 193.63it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 528 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.11730059143155813 | Val Loss: 0.4602213501930237  | Patience 19/20 | LRate: 6.25e-05 | Progress:  20%|██        | 40/200 [00:55<03:42,  1.39s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 0.4364528954029083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:02<00:00, 202.07it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 210.89it/s]\n",
      "Train loss: - | Val Loss: - | Patience 0/20 | LRate: - | Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataset consists of 528 observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.12806143891066313 | Val Loss: 0.4461742043495178  | Patience 19/20 | LRate: 0.000125 | Progress:  16%|█▌        | 31/200 [00:44<04:01,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 0.44590380787849426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:02<00:00, 183.96it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 185.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Hidden Layer Size N. LSTM Layers Loss Weight Range Pre-LSTM FC Layer  \\\n",
       "3                128              4          (1, 0.7)             False   \n",
       "5                128              4          (0.7, 1)             False   \n",
       "0                128              3          (1, 0.7)             False   \n",
       "2                128              3          (0.7, 1)             False   \n",
       "10               256              4      (0.85, 0.85)             False   \n",
       "11               256              4          (0.7, 1)             False   \n",
       "1                128              3      (0.85, 0.85)             False   \n",
       "6                256              3          (1, 0.7)             False   \n",
       "9                256              4          (1, 0.7)             False   \n",
       "7                256              3      (0.85, 0.85)             False   \n",
       "4                128              4      (0.85, 0.85)             False   \n",
       "8                256              3          (0.7, 1)             False   \n",
       "\n",
       "   Final Hidden State Dropout Train Loss  Val Loss  Train HR    Val HR  \n",
       "3                True     0.4   0.152011  0.378862  0.618947  0.490566  \n",
       "5                True     0.4   0.179686   0.44558  0.576842   0.45283  \n",
       "0                True     0.4    0.13289  0.464508  0.633684  0.433962  \n",
       "2                True     0.4   0.149035  0.442882  0.623158  0.433962  \n",
       "10               True     0.4   0.112575  0.436453  0.671579  0.433962  \n",
       "11               True     0.4   0.126958  0.445904  0.696842  0.433962  \n",
       "1                True     0.4   0.124954  0.506611  0.650526  0.415094  \n",
       "6                True     0.4   0.113058  0.426466  0.642105  0.415094  \n",
       "9                True     0.4   0.134458  0.450006  0.612632  0.415094  \n",
       "7                True     0.4   0.120047  0.442854  0.677895  0.377358  \n",
       "4                True     0.4   0.147087  0.472646  0.623158  0.358491  \n",
       "8                True     0.4   0.106744  0.501246  0.709474  0.358491  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layer Size</th>\n",
       "      <th>N. LSTM Layers</th>\n",
       "      <th>Loss Weight Range</th>\n",
       "      <th>Pre-LSTM FC Layer</th>\n",
       "      <th>Final Hidden State</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Val Loss</th>\n",
       "      <th>Train HR</th>\n",
       "      <th>Val HR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.152011</td>\n",
       "      <td>0.378862</td>\n",
       "      <td>0.618947</td>\n",
       "      <td>0.490566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.179686</td>\n",
       "      <td>0.44558</td>\n",
       "      <td>0.576842</td>\n",
       "      <td>0.45283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.13289</td>\n",
       "      <td>0.464508</td>\n",
       "      <td>0.633684</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.149035</td>\n",
       "      <td>0.442882</td>\n",
       "      <td>0.623158</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.112575</td>\n",
       "      <td>0.436453</td>\n",
       "      <td>0.671579</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.126958</td>\n",
       "      <td>0.445904</td>\n",
       "      <td>0.696842</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.124954</td>\n",
       "      <td>0.506611</td>\n",
       "      <td>0.650526</td>\n",
       "      <td>0.415094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.113058</td>\n",
       "      <td>0.426466</td>\n",
       "      <td>0.642105</td>\n",
       "      <td>0.415094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.134458</td>\n",
       "      <td>0.450006</td>\n",
       "      <td>0.612632</td>\n",
       "      <td>0.415094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.120047</td>\n",
       "      <td>0.442854</td>\n",
       "      <td>0.677895</td>\n",
       "      <td>0.377358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.147087</td>\n",
       "      <td>0.472646</td>\n",
       "      <td>0.623158</td>\n",
       "      <td>0.358491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.106744</td>\n",
       "      <td>0.501246</td>\n",
       "      <td>0.709474</td>\n",
       "      <td>0.358491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test",
   "id": "dc37c2f2ab838d9f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T20:42:20.335463Z",
     "start_time": "2025-06-23T20:42:20.331692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# renew with smoothed_data:\n",
    "SAVED_B1_PREDICTOR = SAVED_MODELS / \"predictor_b1\" / \"2025-05-22 10_03_41 LSTM Model RW68 FH14 Layers3 Size256 TrainL0.10641186928842217 ValL1.9110333621501923 TrainHR0.4860040545463562 ValHR0.5328466892242432.pt\"\n",
    "SAVED_B3_PREDICTOR = SAVED_MODELS / \"predictor_b3\" / \"2025-05-22 11_47_10 LSTM Model RW40 FH5 Layers3 Size128 TrainL0.36055382899940014 ValL1.9578219056129456 TrainHR0.547325074672699 ValHR0.529629647731781.pt\"\n",
    "SAVED_C1_PREDICTOR = SAVED_MODELS / \"predictor_c1\" / \"2025-05-22 11_27_18 LSTM Model RW24 FH3 Layers4 Size128 TrainL0.29682125337421894 ValL0.4320639967918396 TrainHR0.5574468374252319 ValHR0.5660377144813538.pt\"\n",
    "ENV_PRICE_FILE = filemgmt.most_recent_file(INTERPOLATED_PRICES, '.csv', '15min')\n",
    "B1_PRICE_FILE = filemgmt.most_recent_file(INTERPOLATED_PRICES, '.csv', '60min')\n",
    "B3_PRICE_FILE = filemgmt.most_recent_file(INTERPOLATED_PRICES, '.csv', '1d')\n",
    "C1_PRICE_FILE = filemgmt.most_recent_file(INTERPOLATED_PRICES, '.csv', '7d')"
   ],
   "id": "7ba6e5eaa23c96",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T20:42:22.424842Z",
     "start_time": "2025-06-23T20:42:21.119137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "c1_predictor = LSTMPredictor(model_load_file_path=SAVED_C1_PREDICTOR,  # based on this, the predictor infers the model's properties\n",
    "                             price_csv_path=C1_PRICE_FILE,\n",
    "                             daily_prediction_hour=20,  # these are necessary data properties which still need to be set\n",
    "                             rolling_window_size=6*4,  # 6 months a 4 weeks hindsight\n",
    "                             forecast_horizon=3,  # 3 weeks ahead\n",
    "                             sampling_rate_minutes=5*14*60,  # 1 week a 5 days from 8 to 22\n",
    "                             )\n",
    "#c1_predictor"
   ],
   "id": "156a461b2d31b314",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No training epochs defined upon initialisation. Define LSTMPredictor.n_train_epochs to start training procedure.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T20:43:19.387892Z",
     "start_time": "2025-06-23T20:43:19.380747Z"
    }
   },
   "cell_type": "code",
   "source": "c1_predictor.price_series",
   "id": "d1e9b7837db560b9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2014-10-23 16:00:00    19.859246\n",
       "2014-10-30 16:00:00    20.091760\n",
       "2014-11-06 16:00:00    20.223222\n",
       "2014-11-13 16:00:00    20.124641\n",
       "2014-11-20 16:00:00    20.842549\n",
       "                         ...    \n",
       "2025-05-01 16:00:00    41.740000\n",
       "2025-05-08 16:00:00    42.600000\n",
       "2025-05-15 16:00:00    42.673310\n",
       "2025-05-22 16:00:00    43.665000\n",
       "2025-05-29 16:00:00    44.030000\n",
       "Name: close, Length: 554, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T20:42:29.537181Z",
     "start_time": "2025-06-23T20:42:29.229359Z"
    }
   },
   "cell_type": "code",
   "source": "c1_predictor.plot_prediction_overview()",
   "id": "483824fbb5f9370c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created rolling window view based on rolling_window_size of 24 and forecast_horizon of 3 with a time unit of 4200 minutes.\n",
      "Target values start at only observation between 20:00 and 21:00 daily.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No observations remain after choosing observations according to prediction hour of 20.\nThis can be due to wrong specification of the sampling rate (currently 4200 min)!",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mc1_predictor\u001B[49m\u001B[43m.\u001B[49m\u001B[43mplot_prediction_overview\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Mobile Documents/com~apple~CloudDocs/PR iCloud/Work/Personal/Programming/Github Repos/hybrid-rl-index-trading/src/pipeline/predictors.py:948\u001B[39m, in \u001B[36mLSTMPredictor.plot_prediction_overview\u001B[39m\u001B[34m(self, data_split, day_slice, X_color, Y_color, pred_color, plot_size)\u001B[39m\n\u001B[32m    945\u001B[39m predictions_per_day = \u001B[32m1\u001B[39m\n\u001B[32m    947\u001B[39m \u001B[38;5;66;03m# select training or validation data:\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m948\u001B[39m predictions = \u001B[38;5;28mself\u001B[39m.predictions_train \u001B[38;5;28;01mif\u001B[39;00m data_split == \u001B[33m'\u001B[39m\u001B[33mtraining\u001B[39m\u001B[33m'\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpredictions_val\u001B[49m\n\u001B[32m    949\u001B[39m X_dates = \u001B[38;5;28mself\u001B[39m.X_dates_train \u001B[38;5;28;01mif\u001B[39;00m data_split == \u001B[33m'\u001B[39m\u001B[33mtraining\u001B[39m\u001B[33m'\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.X_dates_val\n\u001B[32m    950\u001B[39m X = \u001B[38;5;28mself\u001B[39m.X_train \u001B[38;5;28;01mif\u001B[39;00m data_split == \u001B[33m'\u001B[39m\u001B[33mtraining\u001B[39m\u001B[33m'\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.X_val\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Mobile Documents/com~apple~CloudDocs/PR iCloud/Work/Personal/Programming/Github Repos/hybrid-rl-index-trading/src/pipeline/predictors.py:759\u001B[39m, in \u001B[36mLSTMPredictor.predictions_val\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    756\u001B[39m \u001B[38;5;129m@property\u001B[39m\n\u001B[32m    757\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpredictions_val\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    758\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._predictions_val \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m759\u001B[39m         \u001B[38;5;28mself\u001B[39m._predictions_val = \u001B[38;5;28mself\u001B[39m.lstm_model.predict(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdataloader_val\u001B[49m, device=\u001B[38;5;28mself\u001B[39m.device)\n\u001B[32m    760\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._predictions_val\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Mobile Documents/com~apple~CloudDocs/PR iCloud/Work/Personal/Programming/Github Repos/hybrid-rl-index-trading/src/pipeline/predictors.py:580\u001B[39m, in \u001B[36mLSTMPredictor.dataloader_val\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    578\u001B[39m \u001B[38;5;129m@property\u001B[39m\n\u001B[32m    579\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdataloader_val\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m580\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._dataloader_val \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m: \u001B[38;5;28mself\u001B[39m._dataloader_val = DataLoader(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdataset_val\u001B[49m, batch_size=\u001B[38;5;28mself\u001B[39m.batch_size,\n\u001B[32m    581\u001B[39m                                                                        shuffle=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m    582\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._dataloader_val\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Mobile Documents/com~apple~CloudDocs/PR iCloud/Work/Personal/Programming/Github Repos/hybrid-rl-index-trading/src/pipeline/predictors.py:560\u001B[39m, in \u001B[36mLSTMPredictor.dataset_val\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    558\u001B[39m \u001B[38;5;129m@property\u001B[39m\n\u001B[32m    559\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdataset_val\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m560\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m TimeSeriesDataset(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mX_val\u001B[49m, \u001B[38;5;28mself\u001B[39m.Y_val)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Mobile Documents/com~apple~CloudDocs/PR iCloud/Work/Personal/Programming/Github Repos/hybrid-rl-index-trading/src/pipeline/predictors.py:521\u001B[39m, in \u001B[36mLSTMPredictor.X_val\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    519\u001B[39m \u001B[38;5;129m@property\u001B[39m\n\u001B[32m    520\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mX_val\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m521\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._X_val \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m: \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msplit_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    522\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._X_val\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Mobile Documents/com~apple~CloudDocs/PR iCloud/Work/Personal/Programming/Github Repos/hybrid-rl-index-trading/src/pipeline/predictors.py:827\u001B[39m, in \u001B[36mLSTMPredictor.split_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    819\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34msplit_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    820\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    821\u001B[39m \u001B[33;03m    Leverages preprocessing.create_train_validation_split.\u001B[39;00m\n\u001B[32m    822\u001B[39m \n\u001B[32m    823\u001B[39m \u001B[33;03m    Splits training and target values into training and validation split.\u001B[39;00m\n\u001B[32m    824\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m    825\u001B[39m     (\u001B[38;5;28mself\u001B[39m._X_train, \u001B[38;5;28mself\u001B[39m._X_val, \u001B[38;5;28mself\u001B[39m._Y_train, \u001B[38;5;28mself\u001B[39m._Y_val,\n\u001B[32m    826\u001B[39m      \u001B[38;5;28mself\u001B[39m._X_dates_train, \u001B[38;5;28mself\u001B[39m._X_dates_val, \u001B[38;5;28mself\u001B[39m._Y_dates_train, \u001B[38;5;28mself\u001B[39m._Y_dates_val\n\u001B[32m--> \u001B[39m\u001B[32m827\u001B[39m      ) = preprocessing.create_train_validation_split(X=\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mX\u001B[49m,\n\u001B[32m    828\u001B[39m                                                      Y=\u001B[38;5;28mself\u001B[39m.Y,\n\u001B[32m    829\u001B[39m                                                      X_dates=\u001B[38;5;28mself\u001B[39m.X_dates,\n\u001B[32m    830\u001B[39m                                                      Y_dates=\u001B[38;5;28mself\u001B[39m.Y_dates,\n\u001B[32m    831\u001B[39m                                                      verbose=\u001B[38;5;28mself\u001B[39m.verbose,\n\u001B[32m    832\u001B[39m                                                      validation_split=\u001B[38;5;28mself\u001B[39m.validation_split)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Mobile Documents/com~apple~CloudDocs/PR iCloud/Work/Personal/Programming/Github Repos/hybrid-rl-index-trading/src/pipeline/predictors.py:488\u001B[39m, in \u001B[36mLSTMPredictor.X\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    486\u001B[39m \u001B[38;5;129m@property\u001B[39m\n\u001B[32m    487\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mX\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m488\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._X \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m: \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mprepare_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    489\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._X\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Mobile Documents/com~apple~CloudDocs/PR iCloud/Work/Personal/Programming/Github Repos/hybrid-rl-index-trading/src/pipeline/predictors.py:811\u001B[39m, in \u001B[36mLSTMPredictor.prepare_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    798\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mprepare_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    799\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    800\u001B[39m \u001B[33;03m    Leverages preprocessing.create_rolling_window_view().\u001B[39;00m\n\u001B[32m    801\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    808\u001B[39m \u001B[33;03m    This further requires specifying sampling_rate_minutes to find the first entry in that prediction hour.\u001B[39;00m\n\u001B[32m    809\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m    810\u001B[39m     (\u001B[38;5;28mself\u001B[39m._X, \u001B[38;5;28mself\u001B[39m._Y, \u001B[38;5;28mself\u001B[39m._X_dates, \u001B[38;5;28mself\u001B[39m._Y_dates\n\u001B[32m--> \u001B[39m\u001B[32m811\u001B[39m      ) = \u001B[43mpreprocessing\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcreate_rolling_window_view\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_series\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mnormalised_price_series\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    812\u001B[39m \u001B[43m                                                  \u001B[49m\u001B[43mrolling_window_size\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrolling_window_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    813\u001B[39m \u001B[43m                                                  \u001B[49m\u001B[43mforecast_horizon\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mforecast_horizon\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    814\u001B[39m \u001B[43m                                                  \u001B[49m\u001B[43msampling_rate_minutes\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msampling_rate_minutes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    815\u001B[39m \u001B[43m                                                  \u001B[49m\u001B[43mdaily_prediction_hour\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdaily_prediction_hour\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    816\u001B[39m \u001B[43m                                                  \u001B[49m\u001B[43mpredict_before_daily_prediction_hour\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpredict_before_daily_prediction_hour\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    817\u001B[39m \u001B[43m                                                  \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Mobile Documents/com~apple~CloudDocs/PR iCloud/Work/Personal/Programming/Github Repos/hybrid-rl-index-trading/src/pipeline/preprocessing.py:184\u001B[39m, in \u001B[36mcreate_rolling_window_view\u001B[39m\u001B[34m(input_series, rolling_window_size, forecast_horizon, daily_prediction_hour, sampling_rate_minutes, predict_before_daily_prediction_hour, verbose)\u001B[39m\n\u001B[32m    182\u001B[39m         \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mResulting dataset consists of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(X)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m observations.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    183\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m184\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mNo observations remain after choosing observations according to prediction hour of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdaily_prediction_hour\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mThis can be due to wrong specification of the sampling rate (currently \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msampling_rate_minutes\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m min)!\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    186\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m X, Y, X_dates, Y_dates\n",
      "\u001B[31mValueError\u001B[39m: No observations remain after choosing observations according to prediction hour of 20.\nThis can be due to wrong specification of the sampling rate (currently 4200 min)!"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run",
   "id": "dced0343fd4bcec6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T22:04:38.269968Z",
     "start_time": "2025-05-19T22:04:38.266897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "AV_API_KEY_FILE = ROOT / \"private\" / \"Alpha Vantage API Key.txt\"\n",
    "with open(AV_API_KEY_FILE) as file: AV_API_KEY = file.read()\n",
    "\n",
    "sampling_rate_minutes = 15\n",
    "ticker = 'Dax'"
   ],
   "id": "1eb48888dd32c323",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T22:04:39.236887Z",
     "start_time": "2025-05-19T22:04:38.573825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ts = TimeSeries(key=AV_API_KEY, output_format='pandas')\n",
    "recent_dax = ts.get_intraday(ticker, interval=f'{sampling_rate_minutes}min',\n",
    "                             outputsize=\"compact\" if 14 * 60 / sampling_rate_minutes < 100 else \"full\")\n",
    "daily_dax = recent_dax[0][recent_dax[0].index.day_of_year == recent_dax[0].index.day_of_year.max()][\n",
    "    '4. close']  # last day\n",
    "recent_price_data = prep.time_interpolation_new_sampling_rate(daily_dax, '4. close', 'date',\n",
    "                                                              f'{sampling_rate_minutes}min',\n",
    "                                                              manual_operating_hours=(8, 22))\n",
    "recent_price_data"
   ],
   "id": "ce61a1509840068d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        close\n",
       "date                         \n",
       "2025-05-16 08:00:00  43.48750\n",
       "2025-05-16 08:15:00  43.24000\n",
       "2025-05-16 08:30:00  42.92000\n",
       "2025-05-16 08:45:00  42.84000\n",
       "2025-05-16 09:00:00  42.76000\n",
       "2025-05-16 09:15:00  42.78000\n",
       "2025-05-16 09:30:00  42.80000\n",
       "2025-05-16 09:45:00  42.87500\n",
       "2025-05-16 10:00:00  42.89790\n",
       "2025-05-16 10:15:00  42.85000\n",
       "2025-05-16 10:30:00  42.61010\n",
       "2025-05-16 10:45:00  42.70000\n",
       "2025-05-16 11:00:00  42.71000\n",
       "2025-05-16 11:15:00  42.75250\n",
       "2025-05-16 11:30:00  42.79500\n",
       "2025-05-16 11:45:00  42.79490\n",
       "2025-05-16 12:00:00  42.71810\n",
       "2025-05-16 12:15:00  42.76500\n",
       "2025-05-16 12:30:00  42.76000\n",
       "2025-05-16 12:45:00  42.76000\n",
       "2025-05-16 13:00:00  42.85000\n",
       "2025-05-16 13:15:00  42.84500\n",
       "2025-05-16 13:30:00  42.80000\n",
       "2025-05-16 13:45:00  42.86670\n",
       "2025-05-16 14:00:00  42.82000\n",
       "2025-05-16 14:15:00  42.84000\n",
       "2025-05-16 14:30:00  42.89000\n",
       "2025-05-16 14:45:00  42.87400\n",
       "2025-05-16 15:00:00  42.85000\n",
       "2025-05-16 15:15:00  42.86760\n",
       "2025-05-16 15:30:00  42.84450\n",
       "2025-05-16 15:45:00  42.90000\n",
       "2025-05-16 16:00:00  42.50000\n",
       "2025-05-16 16:15:00  43.00000\n",
       "2025-05-16 16:30:00  42.99000\n",
       "2025-05-16 16:45:00  42.98000\n",
       "2025-05-16 17:00:00  42.99000\n",
       "2025-05-16 17:15:00  43.00000\n",
       "2025-05-16 17:30:00  43.00000\n",
       "2025-05-16 17:45:00  43.00000\n",
       "2025-05-16 18:00:00  43.00000\n",
       "2025-05-16 18:15:00  43.00000\n",
       "2025-05-16 18:30:00  42.78390\n",
       "2025-05-16 18:45:00  42.80195\n",
       "2025-05-16 19:00:00  42.82000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-05-16 08:00:00</th>\n",
       "      <td>43.48750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 08:15:00</th>\n",
       "      <td>43.24000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 08:30:00</th>\n",
       "      <td>42.92000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 08:45:00</th>\n",
       "      <td>42.84000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 09:00:00</th>\n",
       "      <td>42.76000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 09:15:00</th>\n",
       "      <td>42.78000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 09:30:00</th>\n",
       "      <td>42.80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 09:45:00</th>\n",
       "      <td>42.87500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 10:00:00</th>\n",
       "      <td>42.89790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 10:15:00</th>\n",
       "      <td>42.85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 10:30:00</th>\n",
       "      <td>42.61010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 10:45:00</th>\n",
       "      <td>42.70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 11:00:00</th>\n",
       "      <td>42.71000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 11:15:00</th>\n",
       "      <td>42.75250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 11:30:00</th>\n",
       "      <td>42.79500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 11:45:00</th>\n",
       "      <td>42.79490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 12:00:00</th>\n",
       "      <td>42.71810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 12:15:00</th>\n",
       "      <td>42.76500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 12:30:00</th>\n",
       "      <td>42.76000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 12:45:00</th>\n",
       "      <td>42.76000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 13:00:00</th>\n",
       "      <td>42.85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 13:15:00</th>\n",
       "      <td>42.84500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 13:30:00</th>\n",
       "      <td>42.80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 13:45:00</th>\n",
       "      <td>42.86670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 14:00:00</th>\n",
       "      <td>42.82000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 14:15:00</th>\n",
       "      <td>42.84000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 14:30:00</th>\n",
       "      <td>42.89000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 14:45:00</th>\n",
       "      <td>42.87400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 15:00:00</th>\n",
       "      <td>42.85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 15:15:00</th>\n",
       "      <td>42.86760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 15:30:00</th>\n",
       "      <td>42.84450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 15:45:00</th>\n",
       "      <td>42.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 16:00:00</th>\n",
       "      <td>42.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 16:15:00</th>\n",
       "      <td>43.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 16:30:00</th>\n",
       "      <td>42.99000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 16:45:00</th>\n",
       "      <td>42.98000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 17:00:00</th>\n",
       "      <td>42.99000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 17:15:00</th>\n",
       "      <td>43.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 17:30:00</th>\n",
       "      <td>43.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 17:45:00</th>\n",
       "      <td>43.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 18:00:00</th>\n",
       "      <td>43.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 18:15:00</th>\n",
       "      <td>43.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 18:30:00</th>\n",
       "      <td>42.78390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 18:45:00</th>\n",
       "      <td>42.80195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 19:00:00</th>\n",
       "      <td>42.82000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T22:04:40.252617Z",
     "start_time": "2025-05-19T22:04:40.008818Z"
    }
   },
   "cell_type": "code",
   "source": "predictor_a2_1.predict(recent_price_data.iloc[:32])",
   "id": "b2b3d71f016ff318",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prices are expected to go DOWN!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([31.8091462 , 31.8301834 , 31.85673586, 31.88494352, 31.91238934,\n",
       "        31.93949301, 31.96582016, 31.99007451, 32.01100482, 32.02798444,\n",
       "        32.04102383, 32.05052384, 32.05705088, 32.06117972, 32.06342963,\n",
       "        32.06423025]),\n",
       " DatetimeIndex(['2025-05-16 16:00:00', '2025-05-16 16:15:00',\n",
       "                '2025-05-16 16:30:00', '2025-05-16 16:45:00',\n",
       "                '2025-05-16 17:00:00', '2025-05-16 17:15:00',\n",
       "                '2025-05-16 17:30:00', '2025-05-16 17:45:00',\n",
       "                '2025-05-16 18:00:00', '2025-05-16 18:15:00',\n",
       "                '2025-05-16 18:30:00', '2025-05-16 18:45:00',\n",
       "                '2025-05-16 19:00:00', '2025-05-16 19:15:00',\n",
       "                '2025-05-16 19:30:00', '2025-05-16 19:45:00'],\n",
       "               dtype='datetime64[ns]', freq='15min'))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "565aa1f84953ed03"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
