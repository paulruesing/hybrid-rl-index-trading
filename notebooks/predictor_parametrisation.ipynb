{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Price Predictor Parameter Optimisation",
   "id": "71b6501c476a85d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T19:56:42.820975Z",
     "start_time": "2025-05-21T19:56:38.424185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import src.utils.file_management as filemgmt\n",
    "import src.pipeline.preprocessing as prep\n",
    "import src.pipeline.predictors as predictors\n",
    "from src.pipeline.predictors import LSTMPredictor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Literal, Union\n",
    "\n",
    "from tqdm import tqdm\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "ec348715c8a0ff56",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T19:56:42.835909Z",
     "start_time": "2025-05-21T19:56:42.831478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ROOT = Path().resolve().parent\n",
    "\n",
    "DATA = ROOT / \"data\"\n",
    "DAILY_PRICES = DATA / \"daily_price_downloads\"\n",
    "MINUTELY_PRICES = DATA / \"minutely_price_downloads\"\n",
    "INTERPOLATED_PRICES = DATA / \"interpolated_prices\"\n",
    "\n",
    "SAVED_MODELS = DATA / \"saved_models\""
   ],
   "id": "e487f3895fe5c86e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parametrisation Short-Term - a2\n",
    "Predict **4 hours** based on **15-minutely price data** of the **last 8 hours**."
   ],
   "id": "afff8d2ce08e1d5a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T11:47:23.089475Z",
     "start_time": "2025-05-22T10:22:20.233908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a2_results = predictors.predictor_parametrisation_loop(evaluate_hit_rate=True,\n",
    "                                                       sort_metric='Val HR',\n",
    "                                                       n_train_epochs=200,\n",
    "                                                       early_stopping_patience=20,\n",
    "                                                       sampling_rate_minutes=15,  # 15 minutes\n",
    "                                                       price_csv_path=filemgmt.most_recent_file(INTERPOLATED_PRICES, '.csv', '15min'),\n",
    "                                                       daily_prediction_hour=16,\n",
    "                                                       predict_before_daily_prediction_hour=False,\n",
    "                                                       rolling_window_size=32,\n",
    "                                                       forecast_horizon=16,\n",
    "                                                       batch_size=64,\n",
    "                                                       validation_split=0.1,\n",
    "                                                       model_save_directory=SAVED_MODELS / \"predictor_a2\",\n",
    "                                                       # parameters to optimise for:\n",
    "                                                       hidden_lstm_layer_size_set=[128, 256],  # 64 (was mostly worse)\n",
    "                                                       n_lstm_layers_set=[3, 4],  # 2 (was mostly worse)\n",
    "                                                       forecast_step_loss_weight_range_set=[(1, .7), (.85, .85),\n",
    "                                                                                            (.7, 1)],\n",
    "                                                       use_pre_lstm_fc_layer_set=[False],  # True (maybe simplicity is key?)\n",
    "                                                       use_final_hidden_state_set=[True],  # False  (settings seems to have negligible impact)\n",
    "                                                       dropout_set=[.4],  # .3  (.4 seems to generalise better, as expected)\n",
    "                                                       )\n",
    "a2_results"
   ],
   "id": "23ec0590be3c0fc5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.038591534859733656 | Val Loss: 2.4626315534114838  | Patience 19/20 | LRate: 6.25e-05 | Progress:  19%|█▉        | 38/200 [02:43<11:37,  4.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.1718326210975647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2468/2468 [00:25<00:00, 98.10it/s] \n",
      "100%|██████████| 275/275 [00:02<00:00, 97.51it/s]\n",
      "Train loss: 0.047490859898971394 | Val Loss: 2.4323862493038177  | Patience 19/20 | LRate: 0.000125 | Progress:  12%|█▏        | 24/200 [01:47<13:10,  4.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.7633748054504395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2468/2468 [00:24<00:00, 102.30it/s]\n",
      "100%|██████████| 275/275 [00:02<00:00, 102.95it/s]\n",
      "Train loss: 0.04521715268492699 | Val Loss: 2.3603419959545135  | Patience 19/20 | LRate: 0.000125 | Progress:  11%|█         | 22/200 [01:39<13:21,  4.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.531826436519623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2468/2468 [00:25<00:00, 98.57it/s] \n",
      "100%|██████████| 275/275 [00:02<00:00, 97.89it/s]\n",
      "Train loss: 0.04311996062460821 | Val Loss: 2.308650553226471  | Patience 19/20 | LRate: 0.000125 | Progress:  12%|█▎        | 25/200 [02:32<17:45,  6.09s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.5630407631397247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2468/2468 [00:31<00:00, 77.89it/s]\n",
      "100%|██████████| 275/275 [00:03<00:00, 78.09it/s]\n",
      "Train loss: 0.04265175528416876 | Val Loss: 2.2614286839962006  | Patience 19/20 | LRate: 0.000125 | Progress:  12%|█▎        | 25/200 [02:34<18:01,  6.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.362072706222534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2468/2468 [00:30<00:00, 81.63it/s]\n",
      "100%|██████████| 275/275 [00:03<00:00, 80.24it/s]\n",
      "Train loss: 0.04233079185360111 | Val Loss: 2.149389535188675  | Patience 19/20 | LRate: 0.000125 | Progress:  13%|█▎        | 26/200 [02:42<18:09,  6.26s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.2570862770080566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2468/2468 [00:31<00:00, 79.33it/s]\n",
      "100%|██████████| 275/275 [00:03<00:00, 80.20it/s]\n",
      "Train loss: 0.041194791439920664 | Val Loss: 2.2919795513153076  | Patience 19/20 | LRate: 0.000125 | Progress:  10%|█         | 21/200 [04:08<35:21, 11.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.733959883451462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2468/2468 [00:34<00:00, 72.14it/s]\n",
      "100%|██████████| 275/275 [00:03<00:00, 72.24it/s]\n",
      "Train loss: 0.043918579060118645 | Val Loss: 2.2990501523017883  | Patience 19/20 | LRate: 0.000125 | Progress:  10%|█         | 20/200 [03:57<35:35, 11.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.162608250975609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2468/2468 [00:34<00:00, 71.36it/s]\n",
      "100%|██████████| 275/275 [00:03<00:00, 72.51it/s]\n",
      "Train loss: 0.036813960286963265 | Val Loss: 1.6997721046209335  | Patience 19/20 | LRate: 3.90625e-06 | Progress:  44%|████▎     | 87/200 [16:47<21:48, 11.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 1.738769382238388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2468/2468 [00:34<00:00, 71.64it/s]\n",
      "100%|██████████| 275/275 [00:03<00:00, 72.01it/s]\n",
      "Train loss: 0.03997202870959882 | Val Loss: 2.719214677810669  | Patience 19/20 | LRate: 0.000125 | Progress:  12%|█▏        | 23/200 [06:03<46:37, 15.80s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.3316901326179504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2468/2468 [00:46<00:00, 53.46it/s]\n",
      "100%|██████████| 275/275 [00:05<00:00, 53.92it/s]\n",
      "Train loss: 0.03491487151768524 | Val Loss: 1.551470622420311  | Patience 19/20 | LRate: 4.8828125e-07 | Progress:  51%|█████     | 102/200 [26:58<25:55, 15.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 1.6844927966594696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2468/2468 [00:46<00:00, 52.90it/s]\n",
      "100%|██████████| 275/275 [00:05<00:00, 52.79it/s]\n",
      "Train loss: 0.04496143452706747 | Val Loss: 2.4055043160915375  | Patience 19/20 | LRate: 0.000125 | Progress:  10%|█         | 20/200 [05:31<49:39, 16.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.465428739786148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2468/2468 [00:46<00:00, 52.95it/s]\n",
      "100%|██████████| 275/275 [00:05<00:00, 52.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Hidden Layer Size N. LSTM Layers Loss Weight Range Pre-LSTM FC Layer  \\\n",
       "10               256              4      (0.85, 0.85)             False   \n",
       "8                256              3          (0.7, 1)             False   \n",
       "2                128              3          (0.7, 1)             False   \n",
       "6                256              3          (1, 0.7)             False   \n",
       "3                128              4          (1, 0.7)             False   \n",
       "7                256              3      (0.85, 0.85)             False   \n",
       "0                128              3          (1, 0.7)             False   \n",
       "5                128              4          (0.7, 1)             False   \n",
       "1                128              3      (0.85, 0.85)             False   \n",
       "4                128              4      (0.85, 0.85)             False   \n",
       "11               256              4          (0.7, 1)             False   \n",
       "9                256              4          (1, 0.7)             False   \n",
       "\n",
       "   Final Hidden State Dropout Train Loss  Val Loss  Train HR    Val HR  \n",
       "10               True     0.4   0.034957  1.684493   0.47812  0.461818  \n",
       "8                True     0.4   0.036902  1.738769  0.469611  0.454545  \n",
       "2                True     0.4   0.043851  2.531826   0.48906  0.447273  \n",
       "6                True     0.4   0.041657   2.73396  0.497569  0.443636  \n",
       "3                True     0.4   0.043735  2.563041  0.476904  0.421818  \n",
       "7                True     0.4   0.041528  2.162608  0.486629  0.421818  \n",
       "0                True     0.4   0.038111  2.171833   0.45624  0.407273  \n",
       "5                True     0.4   0.041998  2.257086  0.427877  0.407273  \n",
       "1                True     0.4   0.045887  2.763375  0.468395  0.403636  \n",
       "4                True     0.4   0.040517  2.362073  0.476094  0.403636  \n",
       "11               True     0.4   0.043683  2.465429   0.45705       0.4  \n",
       "9                True     0.4   0.040324   2.33169  0.481361  0.396364  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layer Size</th>\n",
       "      <th>N. LSTM Layers</th>\n",
       "      <th>Loss Weight Range</th>\n",
       "      <th>Pre-LSTM FC Layer</th>\n",
       "      <th>Final Hidden State</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Val Loss</th>\n",
       "      <th>Train HR</th>\n",
       "      <th>Val HR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.034957</td>\n",
       "      <td>1.684493</td>\n",
       "      <td>0.47812</td>\n",
       "      <td>0.461818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.036902</td>\n",
       "      <td>1.738769</td>\n",
       "      <td>0.469611</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.043851</td>\n",
       "      <td>2.531826</td>\n",
       "      <td>0.48906</td>\n",
       "      <td>0.447273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.041657</td>\n",
       "      <td>2.73396</td>\n",
       "      <td>0.497569</td>\n",
       "      <td>0.443636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.043735</td>\n",
       "      <td>2.563041</td>\n",
       "      <td>0.476904</td>\n",
       "      <td>0.421818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.041528</td>\n",
       "      <td>2.162608</td>\n",
       "      <td>0.486629</td>\n",
       "      <td>0.421818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.038111</td>\n",
       "      <td>2.171833</td>\n",
       "      <td>0.45624</td>\n",
       "      <td>0.407273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.041998</td>\n",
       "      <td>2.257086</td>\n",
       "      <td>0.427877</td>\n",
       "      <td>0.407273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.045887</td>\n",
       "      <td>2.763375</td>\n",
       "      <td>0.468395</td>\n",
       "      <td>0.403636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>2.362073</td>\n",
       "      <td>0.476094</td>\n",
       "      <td>0.403636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.043683</td>\n",
       "      <td>2.465429</td>\n",
       "      <td>0.45705</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.040324</td>\n",
       "      <td>2.33169</td>\n",
       "      <td>0.481361</td>\n",
       "      <td>0.396364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parametrisation Mid-Term - b1\n",
    "Predict **1 day** based on **hourly price data** of the **last week**."
   ],
   "id": "b3cf7ea861098775"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T08:58:47.526465Z",
     "start_time": "2025-05-22T06:52:03.802992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "b1_results = predictors.predictor_parametrisation_loop(evaluate_hit_rate=True,\n",
    "                                                       sort_metric='Val HR',\n",
    "                                                       n_train_epochs=200,\n",
    "                                                       early_stopping_patience=20,\n",
    "                                                       sampling_rate_minutes=60,  # hourly prices\n",
    "                                                       price_csv_path=filemgmt.most_recent_file(INTERPOLATED_PRICES, '.csv', '60min'),\n",
    "                                                       daily_prediction_hour=20,\n",
    "                                                       predict_before_daily_prediction_hour=True,\n",
    "                                                       rolling_window_size=68,\n",
    "                                                       forecast_horizon=14,\n",
    "                                                       batch_size=64,\n",
    "                                                       validation_split=0.1,\n",
    "                                                       model_save_directory=SAVED_MODELS / \"predictor_b1\",\n",
    "                                                       # parameters to optimise for:\n",
    "                                                       hidden_lstm_layer_size_set=[128, 256],  # 64 (was mostly worse)\n",
    "                                                       n_lstm_layers_set=[3, 4],  # 2 (was mostly worse)\n",
    "                                                       forecast_step_loss_weight_range_set=[(1, .7), (.85, .85),\n",
    "                                                                                            (.7, 1)],\n",
    "                                                       use_pre_lstm_fc_layer_set=[False],  # True (maybe simplicity is key?)\n",
    "                                                       use_final_hidden_state_set=[True],  # False  (settings seems to have negligible impact)\n",
    "                                                       dropout_set=[.4],  # .3  (.4 seems to generalise better, as expected)\n",
    "                                                       )\n",
    "b1_results"
   ],
   "id": "4071ed493e688898",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.10543301748111844 | Val Loss: 2.1782477498054504  | Patience 19/20 | LRate: 0.000125 | Progress:  12%|█▎        | 25/200 [02:23<16:45,  5.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.1479981541633606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2465/2465 [00:20<00:00, 117.52it/s]\n",
      "100%|██████████| 274/274 [00:02<00:00, 116.52it/s]\n",
      "Train loss: 0.10312092851381749 | Val Loss: 1.7639930248260498  | Patience 19/20 | LRate: 3.90625e-06 | Progress:  36%|███▌      | 72/200 [06:49<12:07,  5.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.0777192413806915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2465/2465 [00:24<00:00, 99.95it/s] \n",
      "100%|██████████| 274/274 [00:02<00:00, 115.22it/s]\n",
      "Train loss: 0.10946871398482472 | Val Loss: 2.2734962701797485  | Patience 19/20 | LRate: 1.953125e-06 | Progress:  36%|███▌      | 71/200 [06:41<12:09,  5.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.337818756699562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2465/2465 [00:20<00:00, 118.67it/s]\n",
      "100%|██████████| 274/274 [00:02<00:00, 113.95it/s]\n",
      "Train loss: 0.10974332701880485 | Val Loss: 2.162226140499115  | Patience 19/20 | LRate: 0.000125 | Progress:  12%|█▏        | 24/200 [03:49<28:01,  9.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.4202506244182587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2465/2465 [00:35<00:00, 70.24it/s]\n",
      "100%|██████████| 274/274 [00:03<00:00, 70.25it/s]\n",
      "Train loss: 0.0998729313723743 | Val Loss: 1.889426052570343  | Patience 19/20 | LRate: 7.8125e-06 | Progress:  35%|███▌      | 70/200 [11:57<22:12, 10.25s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 1.7904465049505234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2465/2465 [00:40<00:00, 61.17it/s]\n",
      "100%|██████████| 274/274 [00:04<00:00, 61.00it/s]\n",
      "Train loss: 0.10835820145439357 | Val Loss: 2.057125210762024  | Patience 19/20 | LRate: 7.8125e-06 | Progress:  33%|███▎      | 66/200 [10:20<21:00,  9.41s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.1043761074543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2465/2465 [00:35<00:00, 70.37it/s]\n",
      "100%|██████████| 274/274 [00:03<00:00, 70.80it/s]\n",
      "Train loss: 0.09312028042040765 | Val Loss: 2.260948419570923  | Patience 19/20 | LRate: 1.5625e-05 | Progress:  28%|██▊       | 57/200 [18:09<45:33, 19.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.331695467233658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2465/2465 [00:29<00:00, 83.41it/s]\n",
      "100%|██████████| 274/274 [00:03<00:00, 87.52it/s]\n",
      "Train loss: 0.1056306849932298 | Val Loss: 1.9904246628284454  | Patience 19/20 | LRate: 0.000125 | Progress:  12%|█▎        | 25/200 [06:46<47:28, 16.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 1.9110333621501923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2465/2465 [00:44<00:00, 55.70it/s]\n",
      "100%|██████████| 274/274 [00:05<00:00, 51.59it/s]\n",
      "Train loss: 0.10263369721360505 | Val Loss: 2.07333242893219  | Patience 19/20 | LRate: 6.25e-05 | Progress:  24%|██▍       | 48/200 [15:09<48:01, 18.95s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.4295504689216614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2465/2465 [00:29<00:00, 84.91it/s]\n",
      "100%|██████████| 274/274 [00:03<00:00, 85.48it/s]\n",
      "Train loss: 0.09359292197041214 | Val Loss: 2.0738063752651215  | Patience 19/20 | LRate: 7.8125e-06 | Progress:  30%|███       | 61/200 [21:08<48:10, 20.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 1.7711784839630127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2465/2465 [00:53<00:00, 45.73it/s]\n",
      "100%|██████████| 274/274 [00:05<00:00, 53.53it/s]\n",
      "Train loss: 0.10909297317266464 | Val Loss: 1.923585593700409  | Patience 19/20 | LRate: 0.000125 | Progress:  12%|█▏        | 23/200 [08:13<1:03:17, 21.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.12076997756958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2465/2465 [00:43<00:00, 57.23it/s]\n",
      "100%|██████████| 274/274 [00:05<00:00, 54.32it/s]\n",
      "Train loss: 0.11428390408400446 | Val Loss: 2.1895630061626434  | Patience 19/20 | LRate: 0.000125 | Progress:  10%|█         | 21/200 [07:32<1:04:13, 21.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.183376431465149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2465/2465 [00:38<00:00, 64.50it/s]\n",
      "100%|██████████| 274/274 [00:04<00:00, 64.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Hidden Layer Size N. LSTM Layers Loss Weight Range Pre-LSTM FC Layer  \\\n",
       "7                256              3      (0.85, 0.85)             False   \n",
       "1                128              3      (0.85, 0.85)             False   \n",
       "4                128              4      (0.85, 0.85)             False   \n",
       "0                128              3          (1, 0.7)             False   \n",
       "9                256              4          (1, 0.7)             False   \n",
       "2                128              3          (0.7, 1)             False   \n",
       "3                128              4          (1, 0.7)             False   \n",
       "5                128              4          (0.7, 1)             False   \n",
       "6                256              3          (1, 0.7)             False   \n",
       "10               256              4      (0.85, 0.85)             False   \n",
       "11               256              4          (0.7, 1)             False   \n",
       "8                256              3          (0.7, 1)             False   \n",
       "\n",
       "   Final Hidden State Dropout Train Loss  Val Loss  Train HR    Val HR  \n",
       "7                True     0.4   0.106412  1.911033  0.486004  0.532847  \n",
       "1                True     0.4   0.100857  2.077719  0.474239  0.529197  \n",
       "4                True     0.4   0.099665  1.790447   0.46856  0.529197  \n",
       "0                True     0.4    0.10476  2.147998  0.489249  0.521898  \n",
       "9                True     0.4   0.092239  1.771178  0.480325  0.521898  \n",
       "2                True     0.4   0.113377  2.337819  0.476268  0.518248  \n",
       "3                True     0.4   0.108607  2.420251  0.490467  0.518248  \n",
       "5                True     0.4   0.106644  2.104376   0.48357  0.518248  \n",
       "6                True     0.4    0.09268  2.331695  0.467748  0.510949  \n",
       "10               True     0.4   0.108009   2.12077  0.494118  0.510949  \n",
       "11               True     0.4    0.11221  2.183376   0.48641   0.50365  \n",
       "8                True     0.4   0.102196   2.42955  0.486815  0.478102  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layer Size</th>\n",
       "      <th>N. LSTM Layers</th>\n",
       "      <th>Loss Weight Range</th>\n",
       "      <th>Pre-LSTM FC Layer</th>\n",
       "      <th>Final Hidden State</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Val Loss</th>\n",
       "      <th>Train HR</th>\n",
       "      <th>Val HR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.106412</td>\n",
       "      <td>1.911033</td>\n",
       "      <td>0.486004</td>\n",
       "      <td>0.532847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.100857</td>\n",
       "      <td>2.077719</td>\n",
       "      <td>0.474239</td>\n",
       "      <td>0.529197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.099665</td>\n",
       "      <td>1.790447</td>\n",
       "      <td>0.46856</td>\n",
       "      <td>0.529197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.10476</td>\n",
       "      <td>2.147998</td>\n",
       "      <td>0.489249</td>\n",
       "      <td>0.521898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.092239</td>\n",
       "      <td>1.771178</td>\n",
       "      <td>0.480325</td>\n",
       "      <td>0.521898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.113377</td>\n",
       "      <td>2.337819</td>\n",
       "      <td>0.476268</td>\n",
       "      <td>0.518248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.108607</td>\n",
       "      <td>2.420251</td>\n",
       "      <td>0.490467</td>\n",
       "      <td>0.518248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.106644</td>\n",
       "      <td>2.104376</td>\n",
       "      <td>0.48357</td>\n",
       "      <td>0.518248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.09268</td>\n",
       "      <td>2.331695</td>\n",
       "      <td>0.467748</td>\n",
       "      <td>0.510949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.108009</td>\n",
       "      <td>2.12077</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.510949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.11221</td>\n",
       "      <td>2.183376</td>\n",
       "      <td>0.48641</td>\n",
       "      <td>0.50365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.102196</td>\n",
       "      <td>2.42955</td>\n",
       "      <td>0.486815</td>\n",
       "      <td>0.478102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parametrisation Mid-Term - b3\n",
    "Predict **1 week** based on **daily price data** of the **last 2 months**. "
   ],
   "id": "72a7151872847f29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T10:22:20.174036Z",
     "start_time": "2025-05-22T09:45:29.074901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "b3_results = predictors.predictor_parametrisation_loop(evaluate_hit_rate=True,\n",
    "                                                       sort_metric='Val HR',\n",
    "                                                       n_train_epochs=200,\n",
    "                                                       early_stopping_patience=20,\n",
    "                                                       sampling_rate_minutes=60 * 14,  # one day from 8am to 22pm\n",
    "                                                       price_csv_path=filemgmt.most_recent_file(INTERPOLATED_PRICES, '.csv', '1d'),\n",
    "                                                       daily_prediction_hour=20,\n",
    "                                                       predict_before_daily_prediction_hour=True,  # irrelevant\n",
    "                                                       rolling_window_size=40,  # i.e. 2 months á 20 days\n",
    "                                                       forecast_horizon=5,  # i.e. 1 week á 5 days\n",
    "                                                       batch_size=64,\n",
    "                                                       validation_split=0.1,\n",
    "                                                       model_save_directory=SAVED_MODELS / \"predictor_b3\",\n",
    "                                                       # parameters to optimise for:\n",
    "                                                       hidden_lstm_layer_size_set=[128, 256],  # 64 (was mostly worse)\n",
    "                                                       n_lstm_layers_set=[3, 4],  # 2 (was mostly worse)\n",
    "                                                       forecast_step_loss_weight_range_set=[(1, .7), (.85, .85),\n",
    "                                                                                            (.7, 1)],\n",
    "                                                       use_pre_lstm_fc_layer_set=[False],  # True (maybe simplicity is key?)\n",
    "                                                       use_final_hidden_state_set=[True],  # False  (settings seems to have negligible impact)\n",
    "                                                       dropout_set=[.4],  # .3  (.4 seems to generalise better, as expected)\n",
    "                                                       )\n",
    "b3_results"
   ],
   "id": "bcc83a565a9d8e50",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3633599733002484 | Val Loss: 1.9217457175254822  | Patience 19/20 | LRate: 6.25e-05 | Progress:  16%|█▌        | 31/200 [01:30<08:15,  2.93s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 1.9578219056129456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2430/2430 [00:09<00:00, 260.83it/s]\n",
      "100%|██████████| 270/270 [00:01<00:00, 259.59it/s]\n",
      "Train loss: 0.3712230180390179 | Val Loss: 1.92317496240139  | Patience 19/20 | LRate: 0.000125 | Progress:  16%|█▌        | 32/200 [01:35<08:22,  2.99s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.31107160449028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2430/2430 [00:09<00:00, 263.88it/s]\n",
      "100%|██████████| 270/270 [00:01<00:00, 264.32it/s]\n",
      "Train loss: 0.40134902857244015 | Val Loss: 1.7310772836208344  | Patience 19/20 | LRate: 0.000125 | Progress:  14%|█▎        | 27/200 [01:21<08:39,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 1.972681313753128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2430/2430 [00:09<00:00, 267.19it/s]\n",
      "100%|██████████| 270/270 [00:01<00:00, 268.12it/s]\n",
      "Train loss: 0.3458094601519406 | Val Loss: 1.5599791407585144  | Patience 19/20 | LRate: 3.125e-05 | Progress:  20%|█▉        | 39/200 [02:44<11:20,  4.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 1.6891347616910934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2430/2430 [00:11<00:00, 211.56it/s]\n",
      "100%|██████████| 270/270 [00:01<00:00, 211.72it/s]\n",
      "Train loss: 0.38508819369599223 | Val Loss: 2.0278067588806152  | Patience 19/20 | LRate: 0.000125 | Progress:  14%|█▎        | 27/200 [01:57<12:31,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.1556748151779175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2430/2430 [00:11<00:00, 204.35it/s]\n",
      "100%|██████████| 270/270 [00:01<00:00, 205.92it/s]\n",
      "Train loss: 0.4041412160731852 | Val Loss: 2.00884947180748  | Patience 19/20 | LRate: 0.000125 | Progress:  14%|█▍        | 28/200 [01:59<12:15,  4.27s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 1.6586290672421455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2430/2430 [00:11<00:00, 204.90it/s]\n",
      "100%|██████████| 270/270 [00:01<00:00, 205.93it/s]\n",
      "Train loss: 0.3586260718293488 | Val Loss: 1.8847213983535767  | Patience 19/20 | LRate: 0.000125 | Progress:  12%|█▏        | 23/200 [03:06<23:54,  8.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.017342269420624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2430/2430 [00:16<00:00, 147.42it/s]\n",
      "100%|██████████| 270/270 [00:01<00:00, 147.86it/s]\n",
      "Train loss: 0.370660703163594 | Val Loss: 2.334721326828003  | Patience 19/20 | LRate: 0.000125 | Progress:  11%|█         | 22/200 [02:56<23:47,  8.02s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.2051035463809967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2430/2430 [00:14<00:00, 167.68it/s]\n",
      "100%|██████████| 270/270 [00:01<00:00, 172.42it/s]\n",
      "Train loss: 0.3538063205778599 | Val Loss: 2.6640416979789734  | Patience 19/20 | LRate: 0.000125 | Progress:  12%|█▎        | 25/200 [03:16<22:54,  7.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.615083247423172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2430/2430 [00:13<00:00, 176.15it/s]\n",
      "100%|██████████| 270/270 [00:01<00:00, 178.63it/s]\n",
      "Train loss: 0.34425140684470534 | Val Loss: 2.4400920271873474  | Patience 19/20 | LRate: 0.000125 | Progress:  12%|█▏        | 23/200 [04:10<32:05, 10.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 1.9318217933177948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2430/2430 [00:18<00:00, 133.65it/s]\n",
      "100%|██████████| 270/270 [00:02<00:00, 133.33it/s]\n",
      "Train loss: 0.35330283967778087 | Val Loss: 2.2607725858688354  | Patience 19/20 | LRate: 0.000125 | Progress:  12%|█▎        | 25/200 [04:28<31:22, 10.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.0479410886764526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2430/2430 [00:18<00:00, 129.19it/s]\n",
      "100%|██████████| 270/270 [00:02<00:00, 133.42it/s]\n",
      "Train loss: 0.3600581893697381 | Val Loss: 2.123261570930481  | Patience 19/20 | LRate: 0.000125 | Progress:  13%|█▎        | 26/200 [04:41<31:25, 10.84s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 2.2467836141586304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2430/2430 [00:18<00:00, 133.29it/s]\n",
      "100%|██████████| 270/270 [00:02<00:00, 134.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Hidden Layer Size N. LSTM Layers Loss Weight Range Pre-LSTM FC Layer  \\\n",
       "0                128              3          (1, 0.7)             False   \n",
       "9                256              4          (1, 0.7)             False   \n",
       "6                256              3          (1, 0.7)             False   \n",
       "8                256              3          (0.7, 1)             False   \n",
       "1                128              3      (0.85, 0.85)             False   \n",
       "2                128              3          (0.7, 1)             False   \n",
       "3                128              4          (1, 0.7)             False   \n",
       "10               256              4      (0.85, 0.85)             False   \n",
       "4                128              4      (0.85, 0.85)             False   \n",
       "11               256              4          (0.7, 1)             False   \n",
       "7                256              3      (0.85, 0.85)             False   \n",
       "5                128              4          (0.7, 1)             False   \n",
       "\n",
       "   Final Hidden State Dropout Train Loss  Val Loss  Train HR    Val HR  \n",
       "0                True     0.4   0.360554  1.957822  0.547325   0.52963  \n",
       "9                True     0.4   0.345409  1.931822   0.56749  0.522222  \n",
       "6                True     0.4   0.350409  2.017342  0.541975  0.518519  \n",
       "8                True     0.4   0.353528  2.615083  0.602469  0.514815  \n",
       "1                True     0.4   0.361293  2.311072  0.571605  0.511111  \n",
       "2                True     0.4   0.399043  1.972681  0.580658  0.511111  \n",
       "3                True     0.4   0.348699  1.689135  0.559671  0.503704  \n",
       "10               True     0.4   0.355529  2.047941  0.545679  0.503704  \n",
       "4                True     0.4   0.383634  2.155675  0.563374       0.5  \n",
       "11               True     0.4   0.350428  2.246784  0.603704       0.5  \n",
       "7                True     0.4   0.363751  2.205104  0.565432  0.496296  \n",
       "5                True     0.4   0.385532  1.658629  0.545267  0.492593  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layer Size</th>\n",
       "      <th>N. LSTM Layers</th>\n",
       "      <th>Loss Weight Range</th>\n",
       "      <th>Pre-LSTM FC Layer</th>\n",
       "      <th>Final Hidden State</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Val Loss</th>\n",
       "      <th>Train HR</th>\n",
       "      <th>Val HR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.360554</td>\n",
       "      <td>1.957822</td>\n",
       "      <td>0.547325</td>\n",
       "      <td>0.52963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.345409</td>\n",
       "      <td>1.931822</td>\n",
       "      <td>0.56749</td>\n",
       "      <td>0.522222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.350409</td>\n",
       "      <td>2.017342</td>\n",
       "      <td>0.541975</td>\n",
       "      <td>0.518519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.353528</td>\n",
       "      <td>2.615083</td>\n",
       "      <td>0.602469</td>\n",
       "      <td>0.514815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.361293</td>\n",
       "      <td>2.311072</td>\n",
       "      <td>0.571605</td>\n",
       "      <td>0.511111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.399043</td>\n",
       "      <td>1.972681</td>\n",
       "      <td>0.580658</td>\n",
       "      <td>0.511111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.348699</td>\n",
       "      <td>1.689135</td>\n",
       "      <td>0.559671</td>\n",
       "      <td>0.503704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.355529</td>\n",
       "      <td>2.047941</td>\n",
       "      <td>0.545679</td>\n",
       "      <td>0.503704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.383634</td>\n",
       "      <td>2.155675</td>\n",
       "      <td>0.563374</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.350428</td>\n",
       "      <td>2.246784</td>\n",
       "      <td>0.603704</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.363751</td>\n",
       "      <td>2.205104</td>\n",
       "      <td>0.565432</td>\n",
       "      <td>0.496296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.385532</td>\n",
       "      <td>1.658629</td>\n",
       "      <td>0.545267</td>\n",
       "      <td>0.492593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parametrisation Long-Term - c1\n",
    "Predict **3 weeks** based on **weekly price data** of the **last 6 months**."
   ],
   "id": "bb4de7c18182e5d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T09:30:37.581471Z",
     "start_time": "2025-05-22T09:25:45.814764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "c1_results = predictors.predictor_parametrisation_loop(evaluate_hit_rate=True,\n",
    "                                                       sort_metric='Val HR',\n",
    "                                                       n_train_epochs=200,\n",
    "                                                       early_stopping_patience=20,\n",
    "                                                       sampling_rate_minutes=7 * 14 * 60,  # 1 week = 7 days each from 8am to 22pm\n",
    "                                                       price_csv_path=filemgmt.most_recent_file(INTERPOLATED_PRICES, '.csv', '7d'),\n",
    "                                                       daily_prediction_hour=20,\n",
    "                                                       predict_before_daily_prediction_hour=True,  # irrelevant\n",
    "                                                       rolling_window_size=24,  # i.e. 6 months á 4 weeks\n",
    "                                                       forecast_horizon=3,  # i.e. 3 weeks\n",
    "                                                       batch_size=64,\n",
    "                                                       validation_split=0.1,\n",
    "                                                       model_save_directory=SAVED_MODELS / \"predictor_c1\",\n",
    "                                                       # parameters to optimise for:\n",
    "                                                       hidden_lstm_layer_size_set=[128, 256],  # 64 (was mostly worse)\n",
    "                                                       n_lstm_layers_set=[3, 4],  # 2 (was mostly worse)\n",
    "                                                       forecast_step_loss_weight_range_set=[(1, .7), (.85, .85),\n",
    "                                                                                            (.7, 1)],\n",
    "                                                       use_pre_lstm_fc_layer_set=[False],  # True (maybe simplicity is key?)\n",
    "                                                       use_final_hidden_state_set=[True],  # False  (settings seems to have negligible impact)\n",
    "                                                       dropout_set=[.4],  # .3  (.4 seems to generalise better, as expected)\n",
    "                                                       )\n",
    "c1_results"
   ],
   "id": "d0cd00960e0703d2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.24762212112545967 | Val Loss: 0.40837720036506653  | Patience 19/20 | LRate: 0.000125 | Progress:  15%|█▌        | 30/200 [00:10<00:58,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 0.39249199628829956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 470/470 [00:00<00:00, 471.76it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 432.91it/s]\n",
      "Train loss: 0.25973297841846943 | Val Loss: 0.4356614649295807  | Patience 19/20 | LRate: 0.000125 | Progress:  15%|█▌        | 30/200 [00:11<01:06,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 0.4400423765182495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 470/470 [00:01<00:00, 450.71it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 434.71it/s]\n",
      "Train loss: 0.2586831822991371 | Val Loss: 0.49669259786605835  | Patience 19/20 | LRate: 0.000125 | Progress:  18%|█▊        | 36/200 [00:13<01:01,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 0.5106910467147827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 470/470 [00:01<00:00, 456.23it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 370.80it/s]\n",
      "Train loss: 0.23619787767529488 | Val Loss: 0.4288496971130371  | Patience 19/20 | LRate: 0.000125 | Progress:  18%|█▊        | 35/200 [00:19<01:31,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 0.4492229223251343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 470/470 [00:01<00:00, 375.74it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 312.74it/s]\n",
      "Train loss: 0.2544698268175125 | Val Loss: 0.47760796546936035  | Patience 19/20 | LRate: 0.000125 | Progress:  14%|█▍        | 28/200 [00:15<01:33,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 0.474360853433609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 470/470 [00:02<00:00, 204.68it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 314.12it/s]\n",
      "Train loss: 0.2985236272215843 | Val Loss: 0.42853492498397827  | Patience 19/20 | LRate: 0.000125 | Progress:  13%|█▎        | 26/200 [00:13<01:29,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 0.4320639967918396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 470/470 [00:01<00:00, 348.53it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 309.07it/s]\n",
      "Train loss: 0.22528578899800777 | Val Loss: 0.5138872861862183  | Patience 19/20 | LRate: 0.000125 | Progress:  16%|█▌        | 31/200 [00:28<02:35,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 0.5099337697029114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 470/470 [00:02<00:00, 201.91it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 245.28it/s]\n",
      "Train loss: 0.2517979387193918 | Val Loss: 0.4046744704246521  | Patience 19/20 | LRate: 0.000125 | Progress:  14%|█▍        | 28/200 [00:32<03:20,  1.16s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 0.41386863589286804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 470/470 [00:01<00:00, 320.06it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 330.26it/s]\n",
      "Train loss: 0.24053473956882954 | Val Loss: 0.5329576730728149  | Patience 19/20 | LRate: 0.000125 | Progress:  15%|█▌        | 30/200 [00:27<02:34,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 0.5361045002937317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 470/470 [00:01<00:00, 309.07it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 341.00it/s]\n",
      "Train loss: 0.2260698266327381 | Val Loss: 0.4243758022785187  | Patience 19/20 | LRate: 0.000125 | Progress:  13%|█▎        | 26/200 [00:32<03:38,  1.26s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 0.44463443756103516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 470/470 [00:01<00:00, 243.24it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 201.77it/s]\n",
      "Train loss: 0.2403896152973175 | Val Loss: 0.47081395983695984  | Patience 19/20 | LRate: 0.000125 | Progress:  12%|█▎        | 25/200 [00:32<03:48,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 0.47508177161216736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 470/470 [00:02<00:00, 209.59it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 253.67it/s]\n",
      "Train loss: 0.24536843784153461 | Val Loss: 0.545497477054596  | Patience 19/20 | LRate: 0.000125 | Progress:  14%|█▎        | 27/200 [00:32<03:28,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at validation loss of 0.5233075618743896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 470/470 [00:01<00:00, 253.97it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 264.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Hidden Layer Size N. LSTM Layers Loss Weight Range Pre-LSTM FC Layer  \\\n",
       "5                128              4          (0.7, 1)             False   \n",
       "0                128              3          (1, 0.7)             False   \n",
       "3                128              4          (1, 0.7)             False   \n",
       "1                128              3      (0.85, 0.85)             False   \n",
       "2                128              3          (0.7, 1)             False   \n",
       "6                256              3          (1, 0.7)             False   \n",
       "9                256              4          (1, 0.7)             False   \n",
       "10               256              4      (0.85, 0.85)             False   \n",
       "4                128              4      (0.85, 0.85)             False   \n",
       "7                256              3      (0.85, 0.85)             False   \n",
       "8                256              3          (0.7, 1)             False   \n",
       "11               256              4          (0.7, 1)             False   \n",
       "\n",
       "   Final Hidden State Dropout Train Loss  Val Loss  Train HR    Val HR  \n",
       "5                True     0.4   0.296821  0.432064  0.557447  0.566038  \n",
       "0                True     0.4   0.248152  0.392492  0.548936   0.54717  \n",
       "3                True     0.4   0.252073  0.449223  0.580851  0.528302  \n",
       "1                True     0.4   0.249435  0.440042  0.570213  0.509434  \n",
       "2                True     0.4   0.257843  0.510691       0.6  0.509434  \n",
       "6                True     0.4   0.230221  0.509934  0.623404  0.509434  \n",
       "9                True     0.4   0.230707  0.444634  0.604255  0.509434  \n",
       "10               True     0.4   0.242256  0.475082  0.602128  0.509434  \n",
       "4                True     0.4   0.270373  0.474361  0.565957  0.490566  \n",
       "7                True     0.4   0.231334  0.413869  0.608511  0.490566  \n",
       "8                True     0.4   0.244625  0.536105  0.606383  0.471698  \n",
       "11               True     0.4   0.242202  0.523308  0.593617  0.471698  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layer Size</th>\n",
       "      <th>N. LSTM Layers</th>\n",
       "      <th>Loss Weight Range</th>\n",
       "      <th>Pre-LSTM FC Layer</th>\n",
       "      <th>Final Hidden State</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Val Loss</th>\n",
       "      <th>Train HR</th>\n",
       "      <th>Val HR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.296821</td>\n",
       "      <td>0.432064</td>\n",
       "      <td>0.557447</td>\n",
       "      <td>0.566038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.248152</td>\n",
       "      <td>0.392492</td>\n",
       "      <td>0.548936</td>\n",
       "      <td>0.54717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.252073</td>\n",
       "      <td>0.449223</td>\n",
       "      <td>0.580851</td>\n",
       "      <td>0.528302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.249435</td>\n",
       "      <td>0.440042</td>\n",
       "      <td>0.570213</td>\n",
       "      <td>0.509434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.257843</td>\n",
       "      <td>0.510691</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.509434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.230221</td>\n",
       "      <td>0.509934</td>\n",
       "      <td>0.623404</td>\n",
       "      <td>0.509434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>(1, 0.7)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.230707</td>\n",
       "      <td>0.444634</td>\n",
       "      <td>0.604255</td>\n",
       "      <td>0.509434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.242256</td>\n",
       "      <td>0.475082</td>\n",
       "      <td>0.602128</td>\n",
       "      <td>0.509434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.270373</td>\n",
       "      <td>0.474361</td>\n",
       "      <td>0.565957</td>\n",
       "      <td>0.490566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.85, 0.85)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.231334</td>\n",
       "      <td>0.413869</td>\n",
       "      <td>0.608511</td>\n",
       "      <td>0.490566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.244625</td>\n",
       "      <td>0.536105</td>\n",
       "      <td>0.606383</td>\n",
       "      <td>0.471698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.7, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.242202</td>\n",
       "      <td>0.523308</td>\n",
       "      <td>0.593617</td>\n",
       "      <td>0.471698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run",
   "id": "dced0343fd4bcec6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T22:04:38.269968Z",
     "start_time": "2025-05-19T22:04:38.266897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "AV_API_KEY_FILE = ROOT / \"private\" / \"Alpha Vantage API Key.txt\"\n",
    "with open(AV_API_KEY_FILE) as file: AV_API_KEY = file.read()\n",
    "\n",
    "sampling_rate_minutes = 15\n",
    "ticker = 'Dax'"
   ],
   "id": "1eb48888dd32c323",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T22:04:39.236887Z",
     "start_time": "2025-05-19T22:04:38.573825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ts = TimeSeries(key=AV_API_KEY, output_format='pandas')\n",
    "recent_dax = ts.get_intraday(ticker, interval=f'{sampling_rate_minutes}min',\n",
    "                             outputsize=\"compact\" if 14 * 60 / sampling_rate_minutes < 100 else \"full\")\n",
    "daily_dax = recent_dax[0][recent_dax[0].index.day_of_year == recent_dax[0].index.day_of_year.max()][\n",
    "    '4. close']  # last day\n",
    "recent_price_data = prep.time_interpolation_new_sampling_rate(daily_dax, '4. close', 'date',\n",
    "                                                              f'{sampling_rate_minutes}min',\n",
    "                                                              manual_operating_hours=(8, 22))\n",
    "recent_price_data"
   ],
   "id": "ce61a1509840068d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        close\n",
       "date                         \n",
       "2025-05-16 08:00:00  43.48750\n",
       "2025-05-16 08:15:00  43.24000\n",
       "2025-05-16 08:30:00  42.92000\n",
       "2025-05-16 08:45:00  42.84000\n",
       "2025-05-16 09:00:00  42.76000\n",
       "2025-05-16 09:15:00  42.78000\n",
       "2025-05-16 09:30:00  42.80000\n",
       "2025-05-16 09:45:00  42.87500\n",
       "2025-05-16 10:00:00  42.89790\n",
       "2025-05-16 10:15:00  42.85000\n",
       "2025-05-16 10:30:00  42.61010\n",
       "2025-05-16 10:45:00  42.70000\n",
       "2025-05-16 11:00:00  42.71000\n",
       "2025-05-16 11:15:00  42.75250\n",
       "2025-05-16 11:30:00  42.79500\n",
       "2025-05-16 11:45:00  42.79490\n",
       "2025-05-16 12:00:00  42.71810\n",
       "2025-05-16 12:15:00  42.76500\n",
       "2025-05-16 12:30:00  42.76000\n",
       "2025-05-16 12:45:00  42.76000\n",
       "2025-05-16 13:00:00  42.85000\n",
       "2025-05-16 13:15:00  42.84500\n",
       "2025-05-16 13:30:00  42.80000\n",
       "2025-05-16 13:45:00  42.86670\n",
       "2025-05-16 14:00:00  42.82000\n",
       "2025-05-16 14:15:00  42.84000\n",
       "2025-05-16 14:30:00  42.89000\n",
       "2025-05-16 14:45:00  42.87400\n",
       "2025-05-16 15:00:00  42.85000\n",
       "2025-05-16 15:15:00  42.86760\n",
       "2025-05-16 15:30:00  42.84450\n",
       "2025-05-16 15:45:00  42.90000\n",
       "2025-05-16 16:00:00  42.50000\n",
       "2025-05-16 16:15:00  43.00000\n",
       "2025-05-16 16:30:00  42.99000\n",
       "2025-05-16 16:45:00  42.98000\n",
       "2025-05-16 17:00:00  42.99000\n",
       "2025-05-16 17:15:00  43.00000\n",
       "2025-05-16 17:30:00  43.00000\n",
       "2025-05-16 17:45:00  43.00000\n",
       "2025-05-16 18:00:00  43.00000\n",
       "2025-05-16 18:15:00  43.00000\n",
       "2025-05-16 18:30:00  42.78390\n",
       "2025-05-16 18:45:00  42.80195\n",
       "2025-05-16 19:00:00  42.82000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-05-16 08:00:00</th>\n",
       "      <td>43.48750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 08:15:00</th>\n",
       "      <td>43.24000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 08:30:00</th>\n",
       "      <td>42.92000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 08:45:00</th>\n",
       "      <td>42.84000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 09:00:00</th>\n",
       "      <td>42.76000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 09:15:00</th>\n",
       "      <td>42.78000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 09:30:00</th>\n",
       "      <td>42.80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 09:45:00</th>\n",
       "      <td>42.87500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 10:00:00</th>\n",
       "      <td>42.89790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 10:15:00</th>\n",
       "      <td>42.85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 10:30:00</th>\n",
       "      <td>42.61010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 10:45:00</th>\n",
       "      <td>42.70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 11:00:00</th>\n",
       "      <td>42.71000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 11:15:00</th>\n",
       "      <td>42.75250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 11:30:00</th>\n",
       "      <td>42.79500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 11:45:00</th>\n",
       "      <td>42.79490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 12:00:00</th>\n",
       "      <td>42.71810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 12:15:00</th>\n",
       "      <td>42.76500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 12:30:00</th>\n",
       "      <td>42.76000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 12:45:00</th>\n",
       "      <td>42.76000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 13:00:00</th>\n",
       "      <td>42.85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 13:15:00</th>\n",
       "      <td>42.84500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 13:30:00</th>\n",
       "      <td>42.80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 13:45:00</th>\n",
       "      <td>42.86670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 14:00:00</th>\n",
       "      <td>42.82000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 14:15:00</th>\n",
       "      <td>42.84000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 14:30:00</th>\n",
       "      <td>42.89000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 14:45:00</th>\n",
       "      <td>42.87400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 15:00:00</th>\n",
       "      <td>42.85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 15:15:00</th>\n",
       "      <td>42.86760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 15:30:00</th>\n",
       "      <td>42.84450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 15:45:00</th>\n",
       "      <td>42.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 16:00:00</th>\n",
       "      <td>42.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 16:15:00</th>\n",
       "      <td>43.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 16:30:00</th>\n",
       "      <td>42.99000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 16:45:00</th>\n",
       "      <td>42.98000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 17:00:00</th>\n",
       "      <td>42.99000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 17:15:00</th>\n",
       "      <td>43.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 17:30:00</th>\n",
       "      <td>43.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 17:45:00</th>\n",
       "      <td>43.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 18:00:00</th>\n",
       "      <td>43.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 18:15:00</th>\n",
       "      <td>43.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 18:30:00</th>\n",
       "      <td>42.78390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 18:45:00</th>\n",
       "      <td>42.80195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16 19:00:00</th>\n",
       "      <td>42.82000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T22:04:40.252617Z",
     "start_time": "2025-05-19T22:04:40.008818Z"
    }
   },
   "cell_type": "code",
   "source": "predictor_a2_1.predict(recent_price_data.iloc[:32])",
   "id": "b2b3d71f016ff318",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prices are expected to go DOWN!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([31.8091462 , 31.8301834 , 31.85673586, 31.88494352, 31.91238934,\n",
       "        31.93949301, 31.96582016, 31.99007451, 32.01100482, 32.02798444,\n",
       "        32.04102383, 32.05052384, 32.05705088, 32.06117972, 32.06342963,\n",
       "        32.06423025]),\n",
       " DatetimeIndex(['2025-05-16 16:00:00', '2025-05-16 16:15:00',\n",
       "                '2025-05-16 16:30:00', '2025-05-16 16:45:00',\n",
       "                '2025-05-16 17:00:00', '2025-05-16 17:15:00',\n",
       "                '2025-05-16 17:30:00', '2025-05-16 17:45:00',\n",
       "                '2025-05-16 18:00:00', '2025-05-16 18:15:00',\n",
       "                '2025-05-16 18:30:00', '2025-05-16 18:45:00',\n",
       "                '2025-05-16 19:00:00', '2025-05-16 19:15:00',\n",
       "                '2025-05-16 19:30:00', '2025-05-16 19:45:00'],\n",
       "               dtype='datetime64[ns]', freq='15min'))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "565aa1f84953ed03"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
